<!DOCTYPE html>



  


<html class="theme-next muse use-motion" lang>
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hexo, NexT">










<meta property="og:type" content="website">
<meta property="og:title" content="Allent&#39;s Blogs">
<meta property="og:url" content="http://yoursite.com/child/index.html">
<meta property="og:site_name" content="Allent&#39;s Blogs">
<meta property="og:locale" content="default">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Allent&#39;s Blogs">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/child/">





  <title>Allent's Blogs</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="default">

  
  
    
  

  <div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Allent's Blogs</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            Archives
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/child/2019/07/03/SSD训练数据集做客流检测/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Allent Dan">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Allent's Blogs">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/07/03/SSD训练数据集做客流检测/" itemprop="url">SSD训练数据集做客流检测</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-07-03T14:17:38+08:00">
                2019-07-03
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2><span id="windows下使用spyder训练ssd-tensorflow并进行客流检测">Windows下使用spyder训练SSD-TensorFlow，并进行客流检测</span></h2><h3><span id="背景">背景</span></h3><ul>
<li>之前的尝试中，<a href="https://allentdan.github.io/2019/06/08/%E7%94%A8YOLO3%E6%95%B0%E4%BA%BA%E5%A4%B4/" target="_blank" rel="noopener">用yolo v3训练自己的模型并进行客流检测</a>。得到的结果其实已经很好，增加训练样本和训练周期，最后也取得了如下的效果，但是实际在视频中检测时候，抖动现象还是比较严重的。</li>
</ul>
<div><br><img src="https://raw.githubusercontent.com/AllentDan/PedestrianDetection/master/yoloImage/result.png" alt="yolo结果"><br></div>

<ul>
<li>尝试使用另一种实时检测模型SSD，SSD综合了yolo的快捷和Faster RCNN的准确，同时兼备快捷和准确率。</li>
</ul>
<h3><span id="过程">过程</span></h3><ol>
<li><p>先后参考<a href="https://blog.csdn.net/zzz_cming/article/details/81131523" target="_blank" rel="noopener">博客一</a>，<a href="https://blog.csdn.net/duanyajun987/article/details/81564081" target="_blank" rel="noopener">博客二</a>和<a href="https://blog.csdn.net/ngy321/article/details/79901516" target="_blank" rel="noopener">博客三</a>以及对SSD迁移到TensorFlow上的<a href="https://github.com/balancap/SSD-Tensorflow" target="_blank" rel="noopener">工程</a>。其中第三篇博客对我帮助很大，主要是SSD-TensorFlow都是部署在Linux上，或者在windlows使用pycharm的IDE工具，所以对使用其他工具和环境的造成许多困扰。</p>
</li>
<li><p>可以完全按照第二篇博客一步一步向下做，直到第七步。因为不是使用的pycharm，导致无法直接转换文件生成tfrecord。就做了些修改，将linux下的.sh批处理文件改成Windows下的.bat批处理文件。文件内如如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">python tf_convert_data.py ^</span><br><span class="line">--dataset_name pascalvoc ^</span><br><span class="line">--dataset_dir VOCdevkit/VOC2007/ ^</span><br><span class="line">--output_name voc_2007_train ^</span><br><span class="line">--output_dir tfrecords/</span><br><span class="line">pause</span><br></pre></td></tr></table></figure>
</li>
</ol>
<p>读者可以新建TXT文件，然后输入上面内容，换成自己对应的路径，再修改文件名.txt为.bat文件。直接双击运行即可，报错的话，根据内容修改即可。</p>
<ol start="3">
<li>同样，受限于Windows环境和IDE的辣鸡，只好自己编写.bat批处理文件，内如如下：<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">python train_ssd_network.py ^</span><br><span class="line">    --train_dir log2/ ^</span><br><span class="line">    --dataset_dir tfrecords/ ^</span><br><span class="line">    --dataset_name pascalvoc_2007 ^</span><br><span class="line">    --dataset_split_name train ^</span><br><span class="line">    --model_name ssd_300_vgg ^</span><br><span class="line">    --checkpoint_path checkpoints/VGG_VOC0712_SSD_300x300_ft_iter_120000.ckpt ^</span><br><span class="line">    --save_summaries_secs 60 ^</span><br><span class="line">    --save_interval_secs 300 ^</span><br><span class="line">    --weight_decay 0.0005 ^</span><br><span class="line">    --optimizer adam ^</span><br><span class="line">    --learning_rate 0.00003 ^</span><br><span class="line">    --batch_size 16</span><br><span class="line">pause</span><br></pre></td></tr></table></figure>
</li>
</ol>
<p>同样，参照上一个过程做你自己的修改，然后双击运行.bat文件即可，报错修改。训练过程中想终止，按Ctr+C即可。</p>
<h3><span id="问题">问题</span></h3><ul>
<li>问题：训练不收敛，导致很容易像博客一中存在的问题。此外，我本人的训练不收敛情况严重许多，loss可以在10~150间抖动震荡。但是最后测试图片的时候，仍然像第一篇参考博客一样。</li>
<li>办法：后面将所有的图片按最大可能生成tfrecords文件，并且增多图片数量和训练次数。中间还做了其他修改，但是已经忘记了，可以自行尝试。</li>
</ul>
<h3><span id="结果">结果</span></h3><div><br><img src="https://files.gitee.com/group1/M00/08/7A/PaAvDF0jA_6Af3kMAiHUvT4JuLs479.gif?token=f150191b52f5b3b2f6e50347565b46fc&amp;ts=1562653729&amp;attname=mytest6.gif&amp;disposition=inline" alt="GIF"><br></div>

<h3><span id="补充">补充</span></h3><ul>
<li>动图是因为调试数人数的时候，需要一幅图片一幅图片地测试。所以用imageio将几百张图片生成了GIF</li>
<li>考虑到SSD检测效果是比较稳定的，就不做目标跟踪，直接对检测到的人物框处理。</li>
<li>思想就是，下车的人对应的框的位置是相对集中的。所以统计方框的中心点的位置，可以是中心点到原点的欧氏距离，也可以是其他距离。此外，还存在某些人下车不够顺，所以不能直接用方框的y坐标位置，就对y减小到一定值开始算该人下车，当出现该人的框往回时候，又将该人视为上车。以此统计人数，具体仍然有很多细节，就直接贴代码吧。</li>
</ul>
<h3><span id="代码">代码</span></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">Created on Wed Jun 19 10:13:53 2019</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">@author: admin</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">slim = tf.contrib.slim</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> matplotlib.image <span class="keyword">as</span> mpimg</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"></span><br><span class="line">sys.path.append(<span class="string">'../'</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> nets <span class="keyword">import</span> ssd_vgg_300, ssd_common, np_methods</span><br><span class="line"><span class="keyword">from</span> preprocessing <span class="keyword">import</span> ssd_vgg_preprocessing</span><br><span class="line"><span class="keyword">from</span> notebooks <span class="keyword">import</span> visualization</span><br><span class="line"></span><br><span class="line"><span class="comment"># TensorFlow session: grow memory when needed. TF, DO NOT USE ALL MY GPU MEMORY!!!</span></span><br><span class="line">gpu_options = tf.GPUOptions(allow_growth=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">config = tf.ConfigProto(log_device_placement=<span class="literal">False</span>, gpu_options=gpu_options)</span><br><span class="line"></span><br><span class="line">isess = tf.InteractiveSession(config=config)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Input placeholder.</span></span><br><span class="line"></span><br><span class="line">net_shape = (<span class="number">300</span>, <span class="number">300</span>)</span><br><span class="line"></span><br><span class="line">data_format = <span class="string">'NHWC'</span></span><br><span class="line"></span><br><span class="line">img_input = tf.placeholder(tf.uint8, shape=(<span class="literal">None</span>, <span class="literal">None</span>, <span class="number">3</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Evaluation pre-processing: resize to SSD net shape.</span></span><br><span class="line"></span><br><span class="line">image_pre, labels_pre, bboxes_pre, bbox_img = ssd_vgg_preprocessing.preprocess_for_eval(</span><br><span class="line"></span><br><span class="line">    img_input, <span class="literal">None</span>, <span class="literal">None</span>, net_shape, data_format, resize=ssd_vgg_preprocessing.Resize.WARP_RESIZE)</span><br><span class="line"></span><br><span class="line">image_4d = tf.expand_dims(image_pre, <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"><span class="comment"># Define the SSD model.</span></span><br><span class="line"></span><br><span class="line">reuse = <span class="literal">True</span> <span class="keyword">if</span> <span class="string">'ssd_net'</span> <span class="keyword">in</span> locals() <span class="keyword">else</span> <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">ssd_net = ssd_vgg_300.SSDNet()</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> slim.arg_scope(ssd_net.arg_scope(data_format=data_format)):</span><br><span class="line"></span><br><span class="line">    predictions, localisations, _, _ = ssd_net.net(image_4d, is_training=<span class="literal">False</span>, reuse=reuse)</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"><span class="comment"># Restore SSD model.</span></span><br><span class="line"></span><br><span class="line">ckpt_filename = <span class="string">'E:\\Python\\ssd\\log2\\model.ckpt-3380'</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># ckpt_filename = '../checkpoints/VGG_VOC0712_SSD_300x300_ft_iter_120000.ckpt'</span></span><br><span class="line"></span><br><span class="line">isess.run(tf.global_variables_initializer())</span><br><span class="line"></span><br><span class="line">saver = tf.train.Saver()</span><br><span class="line"></span><br><span class="line">saver.restore(isess, ckpt_filename)</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"><span class="comment"># SSD default anchor boxes.</span></span><br><span class="line"></span><br><span class="line">ssd_anchors = ssd_net.anchors(net_shape)</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"><span class="comment"># Main image processing routine.</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">process_image</span><span class="params">(img, select_threshold=<span class="number">0.65</span>, nms_threshold=<span class="number">.15</span>, net_shape=<span class="params">(<span class="number">300</span>, <span class="number">300</span>)</span>)</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Run SSD network.</span></span><br><span class="line"></span><br><span class="line">    rimg, rpredictions, rlocalisations, rbbox_img = isess.run([image_4d, predictions, localisations, bbox_img],</span><br><span class="line"></span><br><span class="line">                                                              feed_dict=&#123;img_input: img&#125;)</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">    <span class="comment"># Get classes and bboxes from the net outputs.</span></span><br><span class="line"></span><br><span class="line">    rclasses, rscores, rbboxes = np_methods.ssd_bboxes_select(</span><br><span class="line"></span><br><span class="line">        rpredictions, rlocalisations, ssd_anchors,</span><br><span class="line"></span><br><span class="line">        select_threshold=select_threshold, img_shape=net_shape, num_classes=<span class="number">21</span>, decode=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">    rbboxes = np_methods.bboxes_clip(rbbox_img, rbboxes)</span><br><span class="line"></span><br><span class="line">    rclasses, rscores, rbboxes = np_methods.bboxes_sort(rclasses, rscores, rbboxes, top_k=<span class="number">400</span>)</span><br><span class="line"></span><br><span class="line">    rclasses, rscores, rbboxes = np_methods.bboxes_nms(rclasses, rscores, rbboxes, nms_threshold=nms_threshold)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Resize bboxes to original image shape. Note: useless for Resize.WARP!</span></span><br><span class="line"></span><br><span class="line">    rbboxes = np_methods.bboxes_resize(rbbox_img, rbboxes)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> rclasses, rscores, rbboxes</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plt_bboxes</span><span class="params">(img, classes, scores, bboxes, pathIndex,out, figsize=<span class="params">(<span class="number">10</span>,<span class="number">10</span>)</span>, linewidth=<span class="number">1.5</span>)</span>:</span></span><br><span class="line">    <span class="string">"""Visualize bounding boxes. Largely inspired by SSD-MXNET!</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    fig = plt.figure(figsize=figsize)</span><br><span class="line">    fig=plt.gcf</span><br><span class="line">    plt.imshow(img)</span><br><span class="line">    height = img.shape[<span class="number">0</span>]</span><br><span class="line">    width = img.shape[<span class="number">1</span>]</span><br><span class="line">    colors = dict()</span><br><span class="line">    outnum=<span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(classes.shape[<span class="number">0</span>]):</span><br><span class="line">        cls_id = int(classes[i])</span><br><span class="line">        <span class="keyword">if</span> cls_id &gt;= <span class="number">0</span>:</span><br><span class="line">            score = scores[i]</span><br><span class="line">            <span class="keyword">if</span> cls_id <span class="keyword">not</span> <span class="keyword">in</span> colors:</span><br><span class="line">                colors[cls_id] = (random.random(), random.random(), random.random())</span><br><span class="line">            ymin = int(bboxes[i, <span class="number">0</span>] * height)</span><br><span class="line">            xmin = int(bboxes[i, <span class="number">1</span>] * width)</span><br><span class="line">            ymax = int(bboxes[i, <span class="number">2</span>] * height)</span><br><span class="line">            xmax = int(bboxes[i, <span class="number">3</span>] * width)</span><br><span class="line">            color=<span class="string">"green"</span></span><br><span class="line">            <span class="keyword">if</span> ymin+ymax&lt;<span class="number">132</span>:</span><br><span class="line">                outnum=outnum++<span class="number">1</span></span><br><span class="line">                color=<span class="string">"red"</span></span><br><span class="line">                linewidth=<span class="number">4</span></span><br><span class="line">            rect = plt.Rectangle((xmin, ymin), xmax - xmin,</span><br><span class="line">                                ymax - ymin, fill=<span class="literal">False</span>,</span><br><span class="line">                                edgecolor=color,</span><br><span class="line">                                linewidth=linewidth)</span><br><span class="line">            plt.gca().add_patch(rect)</span><br><span class="line">            class_name = <span class="string">"person"</span></span><br><span class="line">            plt.gca().text(xmin, ymin - <span class="number">2</span>,</span><br><span class="line">                          <span class="string">'&#123;:s&#125; | &#123;:.3f&#125;'</span>.format(class_name, score),</span><br><span class="line">                          bbox=dict(facecolor=color, alpha=<span class="number">0.5</span>),</span><br><span class="line">                          fontsize=<span class="number">12</span>, color=<span class="string">'white'</span>)</span><br><span class="line">    plt.xlabel(<span class="string">"当前车内人数："</span>+str(len(bboxes)-outnum)+<span class="string">"    已下车人数："</span>+str(out),fontproperties=<span class="string">"SimSun"</span>,size=<span class="number">20</span>)</span><br><span class="line">    plt.savefig(pathIndex)</span><br><span class="line">    <span class="comment"># plt.show()</span></span><br><span class="line">path = <span class="string">'E:/Python/opencv/test2/'</span></span><br><span class="line">image_names = sorted(os.listdir(path))</span><br><span class="line">previous=[<span class="string">"start"</span>]</span><br><span class="line">out=<span class="number">0</span></span><br><span class="line">distance_list=[<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>]</span><br><span class="line">thresh=<span class="number">132</span>/<span class="number">288</span><span class="comment">#判断该乘客是否下车的阈值，该值表示y方向距离</span></span><br><span class="line">thresh_ychange=<span class="number">0.4</span><span class="comment">#y方向的跳动，因为检测到的人物框是有抖动的，可以后面自行增加限制条件</span></span><br><span class="line"><span class="keyword">for</span> image_name <span class="keyword">in</span> image_names:</span><br><span class="line">    img = mpimg.imread(path+image_name)</span><br><span class="line">    rclasses, rscores, rbboxes =  process_image(img)</span><br><span class="line">    now=[]<span class="comment">#存储当前帧</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> rbboxes:</span><br><span class="line">        now.append(&#123;<span class="string">"distance"</span>:i.sum(),<span class="string">"y"</span>:i[<span class="number">0</span>]+i[<span class="number">2</span>]&#125;)</span><br><span class="line">    now=sorted(now, key=<span class="keyword">lambda</span> now : now[<span class="string">"distance"</span>])</span><br><span class="line">    <span class="keyword">if</span> previous==[<span class="string">"start"</span>]:</span><br><span class="line">        previous=now</span><br><span class="line">        <span class="keyword">continue</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">for</span> m,n <span class="keyword">in</span> enumerate(now):</span><br><span class="line">            <span class="keyword">if</span> m&lt;len(previous):</span><br><span class="line">                <span class="keyword">if</span> n[<span class="string">"y"</span>]&lt;thresh <span class="keyword">and</span> previous[m][<span class="string">"y"</span>]&gt;thresh:</span><br><span class="line">                    out=out+<span class="number">1</span></span><br><span class="line">                <span class="keyword">elif</span> n[<span class="string">"y"</span>]&gt;thresh <span class="keyword">and</span> previous[m][<span class="string">"y"</span>]&lt;thresh <span class="keyword">and</span> n[<span class="string">"y"</span>]-previous[m][<span class="string">"y"</span>]&lt;thresh_ychange:</span><br><span class="line">                    out=out<span class="number">-1</span></span><br><span class="line">    previous=now</span><br><span class="line">    plt_bboxes(img,rclasses, rscores, rbboxes, path+<span class="string">'out_'</span>+image_name,out)</span><br></pre></td></tr></table></figure>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/child/2020/12/16/pytorch部署torchscript篇/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Allent Dan">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Allent's Blogs">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/12/16/pytorch部署torchscript篇/" itemprop="url">pytorch部署torchscript篇</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2020-12-16T22:23:29+08:00">
                2020-12-16
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2><span id="toc">[toc]</span></h2><h1><span id="引言">引言</span></h1><p>本文旨在介绍如何在Windows平台使用pytorch的c++ api部署pytorch的CNN模型，本文的部署的模型只有推理功能，这是由于torch::jit不支持部分层或者操作的反向传播。当然即使只是推理也足够许多项目运行了，部署使用的工具有<a href="https://docs.microsoft.com/zh-cn/visualstudio/productinfo/vs2017-system-requirements-vs" target="_blank" rel="noopener">visual studio</a>，<a href="https://opencv.org/" target="_blank" rel="noopener">opencv</a>，<a href="https://pytorch.org/get-started/locally/" target="_blank" rel="noopener">libtorch</a>。</p>
<h1><span id="环境">环境</span></h1><p>本文环境如下：<br>win10平台<br>cuda10.2+cudnn7.6.5<br>双显卡Gtx 1080Ti<br>visual studio 2017 community version<br>opencv 4.5.0<br>libtorch 1.1<br>事实上，除了libtorch是版本有强制要求不低于pytorch版本外（主要是可能存在的api问题，否则也不必）和visual studio的版本要求外，其他如opencv并无版本要求，甚至如果只部署cpu的话，显卡都不是必须。</p>
<h2><span id="visual-studio">visual studio</span></h2><p>visual studio版本最好在2015及以上，本文用2017版本。下载链接在<a href="https://docs.microsoft.com/zh-cn/visualstudio/productinfo/vs2017-system-requirements-vs" target="_blank" rel="noopener">链接1</a>，具体安装过程可以参考<a href="https://www.jianshu.com/p/320aefbc582d" target="_blank" rel="noopener">链接2</a>。打开链接1下载社区版本即可，安装时对于c++程序设计只需安装对应部分，勾选如下：<br><img src="https://upload-images.jianshu.io/upload_images/14545491-8069e52310b857c4.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp" alt="链接2中的图"><br>visual studio的安装并无太多需要赘述，按照教程操作就好。</p>
<h2><span id="opencv">opencv</span></h2><p>截止成文时，opencv版本已到4.5.0。去<a href="https://opencv.org/releases/" target="_blank" rel="noopener">官网</a>下载你想要的版本即可，当然限定平台为Windows平台。opencv的版本如若读者没有特别需要均无影响，本文也试过不同版本，不影响部署。opencv安装也容易，虽然是exe文件，但是实际就是个压缩包，解压到你想要的目录最好。值得注意的是，好的编程习惯很重要，所有程序涉及路径以英文路径为佳，避免出错。</p>
<h2><span id="libtorch">libtorch</span></h2><p>libtorch使用所需要的环境和训练最好保持一致，其中cuda，显卡驱动以及libtorch版本配置一般不应低于训练环境。尤其是libtorch版本要求更为严格，否则部分pytorch的api无法在libtorch中使用。</p>
<p>本文中以libtorch1.1为例介绍，读者也可以下载成文时最新版1.7.1使用，亲测可用。以下载时以release版本为佳，避免一些不必要的错误。<br><img src="https://raw.githubusercontent.com/AllentDan/ImageBase/main/libtorch_deploy/libtorch_download_scene.PNG" alt><br>下载后同样解压到读者想要路径，可以更改好解压名称如下以方便版本管理。<br><img src="https://raw.githubusercontent.com/AllentDan/ImageBase/main/libtorch_deploy/my_dependency.PNG" alt><br>这样下来就已经准备好部署所需要的依赖项。</p>
<h1><span id="例子">例子</span></h1><h2><span id="生成pt文件">生成.pt文件</span></h2><p>接下来以ResNet34分类模型为例尝试部署分类模型。准备一张图片用以判断是否部署成功，本文用例图如下：<br><img src="https://raw.githubusercontent.com/AllentDan/ImageBase/main/libtorch_deploy/flower.jpg" alt><br>接下来先和官网类似生成torchscript模型，亦即本文中的pt文件。本文使用代码如下：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torchvision.models <span class="keyword">import</span> resnet34</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"></span><br><span class="line"><span class="comment">#读取一张图片，并转换成[1,3,224,224]的float张量并归一化</span></span><br><span class="line">image = cv2.imread(<span class="string">"flower.jpg"</span>)</span><br><span class="line">image = cv2.resize(image,(<span class="number">224</span>,<span class="number">224</span>))</span><br><span class="line">input_tensor = torch.tensor(image).permute(<span class="number">2</span>,<span class="number">0</span>,<span class="number">1</span>).unsqueeze(<span class="number">0</span>).float()/<span class="number">225.0</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#定义并加载resnet34模型在imagenet预训练的权重</span></span><br><span class="line">model = resnet34(pretrained=<span class="literal">True</span>)</span><br><span class="line">model.eval()</span><br><span class="line"><span class="comment">#查看模型预测该付图的结果</span></span><br><span class="line">output = model(input_tensor)</span><br><span class="line">output = F.softmax(output,<span class="number">1</span>)</span><br><span class="line">print(<span class="string">"模型预测结果为第&#123;&#125;类，置信度为&#123;&#125;"</span>.format(torch.argmax(output),output.max()))</span><br><span class="line"></span><br><span class="line"><span class="comment">#生成pt模型，按照官网来即可</span></span><br><span class="line">model=model.to(torch.device(<span class="string">"cpu"</span>))</span><br><span class="line">model.eval()</span><br><span class="line">var=torch.ones((<span class="number">1</span>,<span class="number">3</span>,<span class="number">224</span>,<span class="number">224</span>))</span><br><span class="line">traced_script_module = torch.jit.trace(model, var)</span><br><span class="line">traced_script_module.save(<span class="string">"resnet34.pt"</span>)</span><br></pre></td></tr></table></figure></p>
<p>输出结果为：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">模型预测结果为第723类，置信度为0.5916505455970764</span><br></pre></td></tr></table></figure></p>
<p>代码运行结束即可生成.pt文件。</p>
<h2><span id="visual-studio项目配置">Visual Studio项目配置</span></h2><h3><span id="新建visual-studio工程项目">新建Visual Studio工程项目。</span></h3><p>打开Visual Studio 2017，点击文件-&gt;新建-&gt;项目，新建空白的c++项目如下：<br><img src="https://raw.githubusercontent.com/AllentDan/ImageBase/main/libtorch_deploy/newAProject.PNG" alt><br>本文新建项目名称为deploy_test，新建空白项目后右键源文件，点击添加新建项，生成main.cpp。至此，Visual Studio项目的准备工作已做好，接下来时配置项目环境。</p>
<h3><span id="编译环境配置">编译环境配置</span></h3><p>在项目的管理器中设置项目的编译为Release，平台选择x64。如图：<br><img src="https://raw.githubusercontent.com/AllentDan/ImageBase/main/libtorch_deploy/vsRelease64.PNG" alt></p>
<h3><span id="配置项目属性">配置项目属性</span></h3><h4><span id="include">include</span></h4><p>右键项目deploy_test，选择属性进入属性页的配置属性。选择VC++目录，需要添加包含目录和库目录。包含目录配置路径为<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">your path to libtorch\include\torch\csrc\api\include</span><br><span class="line">your path to libtorch\include</span><br><span class="line">your path to opencv\build\include</span><br></pre></td></tr></table></figure></p>
<p>本文的配置结果如下：<br><img src="https://raw.githubusercontent.com/AllentDan/ImageBase/main/libtorch_deploy/include.PNG" alt></p>
<h4><span id="lib">lib</span></h4><p>库目录的配置路径为：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">your path to libtorch\include\lib</span><br><span class="line">your path to opencv\build\x64\vc14\lib</span><br></pre></td></tr></table></figure></p>
<p>其中，vc版本与vs版本对应关系以及opencv与vc版本间的关系见<a href="https://blog.csdn.net/yefcion/article/details/81067030" target="_blank" rel="noopener">链接</a>。VS2017对应版本为vc15，opencv的\build\x64文件夹下同时有vc14和vc15，本文选择了vc14也是可用的（VS高版本向下兼容）。库目录具体配置如下图：<br><img src="https://raw.githubusercontent.com/AllentDan/ImageBase/main/libtorch_deploy/lib.PNG" alt></p>
<h4><span id="link">link</span></h4><p>最后添加链接器，点击链接器-&gt;输入-&gt;附加依赖项，编辑添加库目录中libtorch库目录下所有的.lib文件名。此外，为使用opencv还需添加opencv的.lib文件。本文添加如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">opencv_world450.lib</span><br><span class="line">asmjit.lib</span><br><span class="line">c10.lib</span><br><span class="line">c10d.lib</span><br><span class="line">c10_cuda.lib</span><br><span class="line">caffe2_detectron_ops_gpu.lib</span><br><span class="line">caffe2_module_test_dynamic.lib</span><br><span class="line">caffe2_nvrtc.lib</span><br><span class="line">clog.lib</span><br><span class="line">cpuinfo.lib</span><br><span class="line">dnnl.lib</span><br><span class="line">fbgemm.lib</span><br><span class="line">gloo.lib</span><br><span class="line">gloo_cuda.lib</span><br><span class="line">libprotobuf-lite.lib</span><br><span class="line">libprotobuf.lib</span><br><span class="line">libprotoc.lib</span><br><span class="line">mkldnn.lib</span><br><span class="line">torch.lib</span><br><span class="line">torch_cpu.lib</span><br><span class="line">torch_cuda.lib</span><br></pre></td></tr></table></figure></p>
<h4><span id="dll">dll</span></h4><p>动态链接库需要放入指定位置，有三种做法：</p>
<ul>
<li>将opencv中的\build\x64\vc14\bin文件夹路径放入环境变量path中，libtorch中的lib文件夹同样如此；</li>
<li>拷贝opencv和libtorch中的dll文件到项目的执行目录中；</li>
<li>将opencv和libtorch中的dll路径配置到VS项目中；</li>
</ul>
<p>从省事角度和工程需要角度，一般都是直接拷贝dll到执行目录中。读者可以在项目编译后执行时报错缺啥拷贝啥。</p>
<p>至此，VS项目的配置内容已经完成，下面开始c++代码。</p>
<h3><span id="cpp代码">cpp代码</span></h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;opencv2/opencv.hpp&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;torch/torch.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;torch/script.h&gt; </span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">	<span class="comment">//定义使用cuda</span></span><br><span class="line">	<span class="keyword">auto</span> device = torch::Device(torch::kCUDA,<span class="number">0</span>);</span><br><span class="line">	<span class="comment">//读取图片</span></span><br><span class="line">	<span class="keyword">auto</span> image = cv::imread(<span class="string">"your path to\\flower.jpg"</span>);</span><br><span class="line">	<span class="comment">//缩放至指定大小</span></span><br><span class="line">	cv::resize(image, image, cv::Size(<span class="number">224</span>, <span class="number">224</span>));</span><br><span class="line">	<span class="comment">//转成张量</span></span><br><span class="line">	<span class="keyword">auto</span> input_tensor = torch::from_blob(image.data, &#123; image.rows, image.cols, <span class="number">3</span> &#125;, torch::kByte).permute(&#123; <span class="number">2</span>, <span class="number">0</span>, <span class="number">1</span> &#125;).unsqueeze(<span class="number">0</span>).to(torch::kFloat32) / <span class="number">225.0</span>;</span><br><span class="line">	<span class="comment">//加载模型</span></span><br><span class="line">	<span class="keyword">auto</span> model = torch::jit::load(<span class="string">"your path to\\resnet34.pt"</span>);</span><br><span class="line">	model.to(device);</span><br><span class="line">	model.eval();</span><br><span class="line">	<span class="comment">//前向传播</span></span><br><span class="line">	<span class="keyword">auto</span> output = model.forward(&#123;input_tensor.to(device)&#125;).toTensor();</span><br><span class="line">	output = torch::softmax(output, <span class="number">1</span>);</span><br><span class="line">	<span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; <span class="string">"模型预测结果为第"</span> &lt;&lt; torch::argmax(output) &lt;&lt; <span class="string">"类，置信度为"</span> &lt;&lt; output.max() &lt;&lt; <span class="built_in">std</span>::<span class="built_in">endl</span>;</span><br><span class="line">	<span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>编译执行，代码的输出结果为：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">模型预测结果为第723</span><br><span class="line">[ CUDALongType&#123;&#125; ]类，置信度为0.591652</span><br><span class="line">[ CUDAFloatType&#123;&#125; ]</span><br></pre></td></tr></table></figure></p>
<p>可以发现，torchscript文件推理的结果还是和python的略有不同，不过也已经时小数点后第6位了，一般不会影响最后结果判定。</p>
<h1><span id="一些报错">一些报错</span></h1><h2><span id="错误1无法使用gpu">错误1：无法使用GPU</span></h2><p>目前最新的libtorch依据是1.7+cuda10.2，我也有使用，但是目前发布的版本编译的并不完美。如果官方仍然没有更新的话，以该版本运行的程序可以在CPU中正常使用，但是将模型移至GPU时会出错。相比于正常添加lib文件名，1.7版本的需要在链接器里多添加一句：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/INCLUDE:?warp_size@cuda@at@@YAHXZ</span><br></pre></td></tr></table></figure></p>
<p>其他版本如有遇到类似问题可以同样方式解决，该错误似乎是windows平台导致，此解决方法参考了<a href="https://github.com/pytorch/pytorch/issues/31611" target="_blank" rel="noopener">此链接</a>。</p>
<h2><span id="错误2编译时报错std-不明确的符号">错误2：编译时报错“std”: 不明确的符号</span></h2><p>调整属性页-&gt;属性配置-&gt;c/c++-&gt;语言-&gt;符合模式设置为否即可编译成功。</p>
<h2><span id="错误3缺少dll">错误3：缺少dll</span></h2><p>如果编译成功，执行报错由于找不到xxxx.dll，无法继续执行代码。则解决方式有三：</p>
<ul>
<li>添加对应dll的目录到系统环境变量的path中</li>
<li>在VS项目中配置dll路径</li>
<li>直接将该dll复制粘贴到项目的执行路径下。<br>如果项目不多，建议直接复制粘贴。</li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/child/2020/12/16/My-New-Test/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Allent Dan">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Allent's Blogs">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/12/16/My-New-Test/" itemprop="url">Wind10环境，Visual Studio2017下用Bazel编译Tensorflow(失败转调用编译好的包配置使用Tensorflowc++)</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2020-12-16T22:21:56+08:00">
                2020-12-16
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h3><span id="工具和环境">工具和环境</span></h3><ul>
<li>Windows10；</li>
<li>VS2017；</li>
<li>CUDA9.0；</li>
<li>CUDnn9.0(v7 for CUDA9.0);</li>
<li>eigen3；</li>
<li>bazel-0.24.1-windows-x86_64(版本不是关键，旧版的话会提示你更新)；</li>
<li>Anaconda3 64bit 地址 <a href="https://www.anaconda.com/download/#windows；" target="_blank" rel="noopener">https://www.anaconda.com/download/#windows；</a></li>
</ul>
<h1><span id="readmemd">Readme.md</span></h1><p><img src="https://pandao.github.io/editor.md/images/logos/editormd-logo-180x180.png" alt></p>
<p><img src="https://img.shields.io/github/stars/pandao/editor.md.svg" alt> <img src="https://img.shields.io/github/forks/pandao/editor.md.svg" alt> <img src="https://img.shields.io/github/tag/pandao/editor.md.svg" alt> <img src="https://img.shields.io/github/release/pandao/editor.md.svg" alt> <img src="https://img.shields.io/github/issues/pandao/editor.md.svg" alt> <img src="https://img.shields.io/bower/v/editor.md.svg" alt></p>
<p><strong>目录 (Table of Contents)</strong></p>
<p>[TOCM]</p>
<p>[TOC]</p>
<h1><span id="bazel编译tensorflow的visual-c环境">Bazel编译Tensorflow的Visual C++环境</span></h1><h2><span id="步骤">步骤</span></h2><h3><span id="1">1</span></h3><ul>
<li>按照第二个参考博客安装并配置Bazel，并放入MSYS2根目录C:\msys64；设置两个环境变量 BAZEL_SH，BAZEL_VC，结果在后面下载并编译Tensorflow环节，执行python configure.py发现无反应，遂直接将Bazel.exe复制到Tensorflow文件夹里面，后续需要Bazel的也是直接复制到对应的文件夹</li>
</ul>
<h3><span id="2">2</span></h3><ul>
<li>安装Anaconda3，使用3.6的虚拟环境，在conda Prompt终端输入conda create -n py36 python=3.6</li>
</ul>
<h3><span id="3">3</span></h3><ul>
<li>启动 VS2017 x64 命令行，，激活Anaconda环境，在命令行内执行如下语句cmd.exe “/K” C:\Users\Intel\Anaconda3\Scripts\activate.bat，其中activate.bat文件所在位置需要根据具体情况更改，切换到python36环境，语句为：conda activate py36使用 anaconda 安装 numpy, cython,keras，语句为：conda install numpy cython keras</li>
</ul>
<h3><span id="4">4</span></h3><ul>
<li>编译(仍在上面的命令行下)：下载 tensorflow到 d:/lib，并切换当前目录到 d:/lib/tensorflow此时采用第一个参考博客，Bazel编译部分，编译libtensorflow_cc.so、libtensorflow_framework.so和install_headers，此处主要注意切换目录到相应位置，是切换到里面的tensorflow文件夹，然后将Bazel.exe复制到该目录下，或者不切换，build时候在build后面添加目录也行<pre><code>cd tensorflow
bazel build :libtensorflow_cc.so //（BUILD文件tf_cc_shared_object(name=&quot;libtensorflow_cc.so&quot;)）
bazel build :libtensorflow_framework.so（//BUILD文件tf_cc_shared_object(name=&quot;libtensorflow_framework.so&quot;)）
bazel build :install_headers（//BUILD文件tf_cc_shared_object(name=&quot;install_headers&quot;)）
</code></pre></li>
</ul>
<h3><span id="5">5</span></h3><ul>
<li>多次编译失败后终于成功编译，主要是配置选项设置，可以多做尝试，反正肯定不会一次成功，注意每次尝试将之前的编译产生的bazel_bin等四个文件夹删除</li>
</ul>
<h3><span id="6">6</span></h3><ul>
<li>仍旧安照第一篇博客，将编译后的库文件等文件配置到VS2017，添加H文件引用没变照抄，lib文件因为每个人编译环境和编译选项不同，不要用别人的，自己将要bazel-bin中所有.lib文件都列出来，这需要写一个批量处理程序，可以用python写一个，就很快然后，链接器-&gt;输入-&gt;附加依赖项添加.lib，链接器-&gt;常规-&gt;附加库目录添加lib路径，bazel-bin\tensorflow\core\文件下所有lib文件以及子目录下的所有lib文件最后，将core文件夹里面的lib文件添加到链接器-&gt;命令行-&gt;其他选项添加/WHOLEARCHIVE:*.lib</li>
</ul>
<h3><span id="7">7</span></h3><ul>
<li>结果仍然是失败，显示很多未解析的外部符号，问csdn网友得到回答是bazel没有把其他的lb连接到libtensorflow_cc.lib的问题最后选择放弃，直接用第三个博客里面网友编译好的Release版本，我放到Release文件夹了，可直接获取使用。</li>
</ul>
<p>##参考链接</p>
<p>#####资料一 <a href="https://blog.csdn.net/robothn/article/details/86157724" target="_blank" rel="noopener">TensorFlow 1.13 在 windows 上的构建</a></p>
<p>#####资料二 <a href="https://blog.csdn.net/jin739738709/article/details/86705735" target="_blank" rel="noopener">【软件安装】WIN10 + Tensorflow1.12 C++接口 + Cmake编译 + Bazel编译 + C++接口</a></p>
<p>#####资料三 <a href="https://blog.csdn.net/dageda1991/article/details/79721333" target="_blank" rel="noopener">windows10+vs2015下编译GPU版本tensorflow得到lib和dll（附带C++ inference示例）</a></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/child/2019/07/10/以AlexNet为例分析pytorch/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Allent Dan">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Allent's Blogs">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/07/10/以AlexNet为例分析pytorch/" itemprop="url">以AlexNet为例分析pytorch</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-07-10T10:07:01+08:00">
                2019-07-10
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1><span id="以alexnet分析对比pytorch和tensorflow">以AlexNet分析，对比pytorch和TensorFlow</span></h1><h3><span id="背景">背景</span></h3><ul>
<li>先前的深度学习都是使用的TensorFlow框架的，这是因为TensorFlow占领市场较早，生态社区建立得早，但是不得不说，tf仍然是公认的难用。</li>
<li>使用pytorch，在pytorch官网上稍微花点时间，就可以部署好。比原本从python到C++部署TensorFlow的时间缩短好几倍。</li>
<li>另外pytorch也是公认的易于上手，相比TensorFlow这种反人类的设计，可以说非常人性化了</li>
<li>这篇博客就是以AlexNet为例，一步步分析网络。再对比TensorFlow和pytorch的不同，也算是是为了学习。</li>
</ul>
<h3><span id="分析网络">分析网络</span></h3><p>先上个网络结构图，这个图片上一篇博文里面已经放过了，基本表示了8层网络的结构</p>
<p><div><br><img src="https://www.mdpi.com/remotesensing/remotesensing-09-00848/article_deploy/html/images/remotesensing-09-00848-g003.png" alt="AlexNet"><br></div><br>输入图片是227*227的RGB三通道图片，先后经过五个卷积层，和三个全连接层，得到输出。这里面五个卷积层：<br><img src="https://files.gitee.com/group1/M00/08/81/PaAvDF0lTUaAVvL2AACvLS0NhAA978.png?token=27ff2ffb06d22e0ba7bc7876f2a35f73&amp;ts=1562725721&amp;attname=AlexNet%E5%8D%B7%E7%A7%AF%E5%B1%82.png&amp;disposition=inline" alt></p>
<ul>
<li><p>卷积层的作用就是提取信息，减维度。第二个卷积层为例，参数有：<br>Conv_input卷积输入，<br>Kernal_size卷积核大小,<br>Kernal_nums卷积核数目,<br>Stride步长<br>Pad补丁<br>Conv_output卷积输出<br>假设输入是等高宽的，则输出就表示成：<br>输出宽（高）=（输入的宽（高）-卷积核宽（高）+2*补丁）/ 步长+1<br>输出通道数 = 卷积核数目</p>
</li>
<li><p>池化层，暴力降维。以第一个池化层为例，参数有<br>Pool_input池化输入<br>Kernal_size卷积核大小<br>Stride步长<br>Pool_output卷积输出<br>同样假设输入等宽高，输出计算：<br>池化输出 = 宽（高）=（输入的宽（高）-卷积核宽（高））/ 步长+1</p>
</li>
<li><p>全连接层<br><div><br><img src="https://files.gitee.com/group1/M00/08/81/PaAvDF0lTVmAHh_sAAAz2-xyaVA979.png?token=26675845e73f20f8e4cf0209d5a4949c&amp;ts=1562725721&amp;attname=AlexNet%E5%85%A8%E8%BF%9E%E6%8E%A5%E5%B1%82.png&amp;disposition=inline" alt><br></div><br>全连接层没啥好说的，就是映射。下面就是AlexNet公认的几个贡献：</p>
</li>
</ul>
<ol>
<li>ReLU作为激活函数</li>
<li>Dropout避免模型过拟合</li>
<li>最大池化</li>
<li>提出LRN层</li>
<li>GPU加速</li>
</ol>
<h3><span id="tensorflow下的alexnet">TensorFlow下的AlexNet</span></h3><p>代码使用来源：<a href="https://blog.csdn.net/sinat_29957455/article/details/80657517" target="_blank" rel="noopener">修炼之路</a><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#第一层卷积层</span></span><br><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">"conv1"</span>) <span class="keyword">as</span> scope:</span><br><span class="line">    <span class="comment">#设置卷积核11×11,3通道,64个卷积核</span></span><br><span class="line">    kernel1 = tf.Variable(tf.truncated_normal([<span class="number">11</span>,<span class="number">11</span>,<span class="number">3</span>,<span class="number">64</span>],mean=<span class="number">0</span>,stddev=<span class="number">0.1</span>,</span><br><span class="line">                                              dtype=tf.float32),name=<span class="string">"weights"</span>)</span><br><span class="line">    <span class="comment">#卷积,卷积的横向步长和竖向步长都为4</span></span><br><span class="line">    conv = tf.nn.conv2d(images,kernel1,[<span class="number">1</span>,<span class="number">4</span>,<span class="number">4</span>,<span class="number">1</span>],padding=<span class="string">"SAME"</span>)</span><br><span class="line">    <span class="comment">#初始化偏置</span></span><br><span class="line">    biases = tf.Variable(tf.constant(<span class="number">0</span>,shape=[<span class="number">64</span>],dtype=tf.float32),trainable=<span class="literal">True</span>,name=<span class="string">"biases"</span>)</span><br><span class="line">    bias = tf.nn.bias_add(conv,biases)</span><br><span class="line">    <span class="comment">#RELU激活函数</span></span><br><span class="line">    conv1 = tf.nn.relu(bias,name=scope)</span><br><span class="line">    <span class="comment">#输出该层的信息</span></span><br><span class="line">    print_tensor_info(conv1)</span><br><span class="line">    <span class="comment">#统计参数</span></span><br><span class="line">    parameters += [kernel1,biases]</span><br><span class="line">    <span class="comment">#lrn处理</span></span><br><span class="line">    lrn1 = tf.nn.lrn(conv1,<span class="number">4</span>,bias=<span class="number">1</span>,alpha=<span class="number">1e-3</span>/<span class="number">9</span>,beta=<span class="number">0.75</span>,name=<span class="string">"lrn1"</span>)</span><br><span class="line">    <span class="comment">#最大池化</span></span><br><span class="line">    pool1 = tf.nn.max_pool(lrn1,ksize=[<span class="number">1</span>,<span class="number">3</span>,<span class="number">3</span>,<span class="number">1</span>],strides=[<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>,<span class="number">1</span>],padding=<span class="string">"VALID"</span>,name=<span class="string">"pool1"</span>)</span><br><span class="line">    <span class="comment">#输出该层信息</span></span><br><span class="line">    print_tensor_info(pool1)</span><br><span class="line"></span><br><span class="line"><span class="comment">#第二层卷积层</span></span><br><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">"conv2"</span>) <span class="keyword">as</span> scope:</span><br><span class="line">    <span class="comment">#初始化权重</span></span><br><span class="line">    kernel2 = tf.Variable(tf.truncated_normal([<span class="number">5</span>,<span class="number">5</span>,<span class="number">64</span>,<span class="number">192</span>],dtype=tf.float32,stddev=<span class="number">0.1</span>)</span><br><span class="line">                          ,name=<span class="string">"weights"</span>)</span><br><span class="line">    conv = tf.nn.conv2d(pool1,kernel2,[<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>],padding=<span class="string">"SAME"</span>)</span><br><span class="line">    <span class="comment">#初始化偏置</span></span><br><span class="line">    biases = tf.Variable(tf.constant(<span class="number">0</span>,dtype=tf.float32,shape=[<span class="number">192</span>])</span><br><span class="line">                         ,trainable=<span class="literal">True</span>,name=<span class="string">"biases"</span>)</span><br><span class="line">    bias = tf.nn.bias_add(conv,biases)</span><br><span class="line">    <span class="comment">#RELU激活</span></span><br><span class="line">    conv2 = tf.nn.relu(bias,name=scope)</span><br><span class="line">    print_tensor_info(conv2)</span><br><span class="line">    parameters += [kernel2,biases]</span><br><span class="line">    <span class="comment">#LRN</span></span><br><span class="line">    lrn2 = tf.nn.lrn(conv2,<span class="number">4</span>,<span class="number">1.0</span>,alpha=<span class="number">1e-3</span>/<span class="number">9</span>,beta=<span class="number">0.75</span>,name=<span class="string">"lrn2"</span>)</span><br><span class="line">    <span class="comment">#最大池化</span></span><br><span class="line">    pool2 = tf.nn.max_pool(lrn2,[<span class="number">1</span>,<span class="number">3</span>,<span class="number">3</span>,<span class="number">1</span>],[<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>,<span class="number">1</span>],padding=<span class="string">"VALID"</span>,name=<span class="string">"pool2"</span>)</span><br><span class="line">    print_tensor_info(pool2)</span><br><span class="line"></span><br><span class="line"><span class="comment">#第三层卷积层</span></span><br><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">"conv3"</span>) <span class="keyword">as</span> scope:</span><br><span class="line">    <span class="comment">#初始化权重</span></span><br><span class="line">    kernel3 = tf.Variable(tf.truncated_normal([<span class="number">3</span>,<span class="number">3</span>,<span class="number">192</span>,<span class="number">384</span>],dtype=tf.float32,stddev=<span class="number">0.1</span>)</span><br><span class="line">                          ,name=<span class="string">"weights"</span>)</span><br><span class="line">    conv = tf.nn.conv2d(pool2,kernel3,strides=[<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>],padding=<span class="string">"SAME"</span>)</span><br><span class="line">    biases = tf.Variable(tf.constant(<span class="number">0.0</span>,shape=[<span class="number">384</span>],dtype=tf.float32),trainable=<span class="literal">True</span>,name=<span class="string">"biases"</span>)</span><br><span class="line">    bias = tf.nn.bias_add(conv,biases)</span><br><span class="line">    <span class="comment">#RELU激活层</span></span><br><span class="line">    conv3 = tf.nn.relu(bias,name=scope)</span><br><span class="line">    parameters += [kernel3,biases]</span><br><span class="line">    print_tensor_info(conv3)</span><br><span class="line"></span><br><span class="line"><span class="comment">#第四层卷积层</span></span><br><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">"conv4"</span>) <span class="keyword">as</span> scope:</span><br><span class="line">    <span class="comment">#初始化权重</span></span><br><span class="line">    kernel4 = tf.Variable(tf.truncated_normal([<span class="number">3</span>,<span class="number">3</span>,<span class="number">384</span>,<span class="number">256</span>],stddev=<span class="number">0.1</span>,dtype=tf.float32),</span><br><span class="line">                          name=<span class="string">"weights"</span>)</span><br><span class="line">    <span class="comment">#卷积</span></span><br><span class="line">    conv = tf.nn.conv2d(conv3,kernel4,strides=[<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>],padding=<span class="string">"SAME"</span>)</span><br><span class="line">    biases = tf.Variable(tf.constant(<span class="number">0.0</span>,dtype=tf.float32,shape=[<span class="number">256</span>]),trainable=<span class="literal">True</span>,name=<span class="string">"biases"</span>)</span><br><span class="line">    bias = tf.nn.bias_add(conv,biases)</span><br><span class="line">    <span class="comment">#RELU激活</span></span><br><span class="line">    conv4 = tf.nn.relu(bias,name=scope)</span><br><span class="line">    parameters += [kernel4,biases]</span><br><span class="line">    print_tensor_info(conv4)</span><br><span class="line"></span><br><span class="line"><span class="comment">#第五层卷积层</span></span><br><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">"conv5"</span>) <span class="keyword">as</span> scope:</span><br><span class="line">    <span class="comment">#初始化权重</span></span><br><span class="line">    kernel5 = tf.Variable(tf.truncated_normal([<span class="number">3</span>,<span class="number">3</span>,<span class="number">256</span>,<span class="number">256</span>],stddev=<span class="number">0.1</span>,dtype=tf.float32),</span><br><span class="line">                          name=<span class="string">"weights"</span>)</span><br><span class="line">    conv = tf.nn.conv2d(conv4,kernel5,strides=[<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>],padding=<span class="string">"SAME"</span>)</span><br><span class="line">    biases = tf.Variable(tf.constant(<span class="number">0.0</span>,dtype=tf.float32,shape=[<span class="number">256</span>]),name=<span class="string">"biases"</span>)</span><br><span class="line">    bias = tf.nn.bias_add(conv,biases)</span><br><span class="line">    <span class="comment">#REUL激活层</span></span><br><span class="line">    conv5 = tf.nn.relu(bias)</span><br><span class="line">    parameters += [kernel5,bias]</span><br><span class="line">    <span class="comment">#最大池化</span></span><br><span class="line">    pool5 = tf.nn.max_pool(conv5,[<span class="number">1</span>,<span class="number">3</span>,<span class="number">3</span>,<span class="number">1</span>],[<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>,<span class="number">1</span>],padding=<span class="string">"VALID"</span>,name=<span class="string">"pool5"</span>)</span><br><span class="line">    print_tensor_info(pool5)</span><br><span class="line"></span><br><span class="line"><span class="comment">#第六层全连接层</span></span><br><span class="line">pool5 = tf.reshape(pool5,(<span class="number">-1</span>,<span class="number">6</span>*<span class="number">6</span>*<span class="number">256</span>))</span><br><span class="line">weight6 = tf.Variable(tf.truncated_normal([<span class="number">6</span>*<span class="number">6</span>*<span class="number">256</span>,<span class="number">4096</span>],stddev=<span class="number">0.1</span>,dtype=tf.float32),</span><br><span class="line">                       name=<span class="string">"weight6"</span>)</span><br><span class="line">ful_bias1 = tf.Variable(tf.constant(<span class="number">0.0</span>,dtype=tf.float32,shape=[<span class="number">4096</span>]),name=<span class="string">"ful_bias1"</span>)</span><br><span class="line">ful_con1 = tf.nn.relu(tf.add(tf.matmul(pool5,weight6),ful_bias1))</span><br><span class="line"> </span><br><span class="line"><span class="comment">#第七层第二层全连接层</span></span><br><span class="line">weight7 = tf.Variable(tf.truncated_normal([<span class="number">4096</span>,<span class="number">4096</span>],stddev=<span class="number">0.1</span>,dtype=tf.float32),</span><br><span class="line">                      name=<span class="string">"weight7"</span>)</span><br><span class="line">ful_bias2 = tf.Variable(tf.constant(<span class="number">0.0</span>,dtype=tf.float32,shape=[<span class="number">4096</span>]),name=<span class="string">"ful_bias2"</span>)</span><br><span class="line">ful_con2 = tf.nn.relu(tf.add(tf.matmul(ful_con1,weight7),ful_bias2))</span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment">#第八层第三层全连接层</span></span><br><span class="line">weight8 = tf.Variable(tf.truncated_normal([<span class="number">4096</span>,<span class="number">1000</span>],stddev=<span class="number">0.1</span>,dtype=tf.float32),</span><br><span class="line">                      name=<span class="string">"weight8"</span>)</span><br><span class="line">ful_bias3 = tf.Variable(tf.constant(<span class="number">0.0</span>,dtype=tf.float32,shape=[<span class="number">1000</span>]),name=<span class="string">"ful_bias3"</span>)</span><br><span class="line">ful_con3 = tf.nn.relu(tf.add(tf.matmul(ful_con2,weight8),ful_bias3))</span><br><span class="line"> </span><br><span class="line"><span class="comment">#softmax层</span></span><br><span class="line">weight9 = tf.Variable(tf.truncated_normal([<span class="number">1000</span>,<span class="number">10</span>],stddev=<span class="number">0.1</span>),dtype=tf.float32,name=<span class="string">"weight9"</span>)</span><br><span class="line">bias9 = tf.Variable(tf.constant(<span class="number">0.0</span>,shape=[<span class="number">10</span>]),dtype=tf.float32,name=<span class="string">"bias9"</span>)</span><br><span class="line">output_softmax = tf.nn.softmax(tf.matmul(ful_con3,weight9)+bias9)</span><br></pre></td></tr></table></figure></p>
<h3><span id="pytorch下的alexnet">pytorch下的AlexNet</span></h3><p>代码来源：<a href="https://blog.csdn.net/sjtuxx_lee/article/details/83048006" target="_blank" rel="noopener">sjtu_leexx</a><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">BuildAlexNet</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, model_type, n_output)</span>:</span></span><br><span class="line">        super(BuildAlexNet, self).__init__()</span><br><span class="line">        self.model_type = model_type</span><br><span class="line">        <span class="keyword">if</span> model_type == <span class="string">'pre'</span>:</span><br><span class="line">            model = models.alexnet(pretrained=<span class="literal">True</span>)</span><br><span class="line">            self.features = model.features</span><br><span class="line">            fc1 = nn.Linear(<span class="number">9216</span>, <span class="number">4096</span>)</span><br><span class="line">            fc1.bias = model.classifier[<span class="number">1</span>].bias</span><br><span class="line">            fc1.weight = model.classifier[<span class="number">1</span>].weight</span><br><span class="line">            </span><br><span class="line">            fc2 = nn.Linear(<span class="number">4096</span>, <span class="number">4096</span>)</span><br><span class="line">            fc2.bias = model.classifier[<span class="number">4</span>].bias</span><br><span class="line">            fc2.weight = model.classifier[<span class="number">4</span>].weight</span><br><span class="line">            </span><br><span class="line">            self.classifier = nn.Sequential(</span><br><span class="line">                    nn.Dropout(),</span><br><span class="line">                    fc1,</span><br><span class="line">                    nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line">                    nn.Dropout(),</span><br><span class="line">                    fc2,</span><br><span class="line">                    nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line">                    nn.Linear(<span class="number">4096</span>, n_output))  </span><br><span class="line">            <span class="comment">#或者直接修改为</span></span><br><span class="line"><span class="comment">#            model.classifier[6]==nn.Linear(4096,n_output)</span></span><br><span class="line"><span class="comment">#            self.classifier = model.classifier</span></span><br><span class="line">        <span class="keyword">if</span> model_type == <span class="string">'new'</span>:</span><br><span class="line">            self.features = nn.Sequential(</span><br><span class="line">                    nn.Conv2d(<span class="number">3</span>, <span class="number">64</span>, <span class="number">11</span>, <span class="number">4</span>, <span class="number">2</span>),</span><br><span class="line">                    nn.ReLU(inplace = <span class="literal">True</span>),</span><br><span class="line">                    nn.MaxPool2d(<span class="number">3</span>, <span class="number">2</span>, <span class="number">0</span>),</span><br><span class="line">                    nn.Conv2d(<span class="number">64</span>, <span class="number">192</span>, <span class="number">5</span>, <span class="number">1</span>, <span class="number">2</span>),</span><br><span class="line">                    nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line">                    nn.MaxPool2d(<span class="number">3</span>, <span class="number">2</span>, <span class="number">0</span>),</span><br><span class="line">                    nn.Conv2d(<span class="number">192</span>, <span class="number">384</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                    nn.ReLU(inplace = <span class="literal">True</span>),</span><br><span class="line">                    nn.Conv2d(<span class="number">384</span>, <span class="number">256</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                    nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line">                    nn.MaxPool2d(<span class="number">3</span>, <span class="number">2</span>, <span class="number">0</span>))</span><br><span class="line">            self.classifier = nn.Sequential(</span><br><span class="line">                    nn.Dropout(),</span><br><span class="line">                    nn.Linear(<span class="number">9216</span>, <span class="number">4096</span>),</span><br><span class="line">                    nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line">                    nn.Dropout(),</span><br><span class="line">                    nn.Linear(<span class="number">4096</span>, <span class="number">4096</span>),</span><br><span class="line">                    nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line">                    nn.Linear(<span class="number">4096</span>, n_output))</span><br><span class="line">            </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        x = self.features(x)</span><br><span class="line">        x = x.view(x.size(<span class="number">0</span>), <span class="number">-1</span>)</span><br><span class="line">        out  = self.classifier(x)</span><br><span class="line">        <span class="keyword">return</span> out</span><br></pre></td></tr></table></figure></p>
<h3><span id="直观比较">直观比较</span></h3><ul>
<li>直观感受就是pytorch比TensorFlow好多了。</li>
<li>同时pytorch是有预训练数据的，可以用来迁移学习。</li>
<li>Tensorflow供给用户修改的参数实在太多了，细致到每一层的命名。而pytorch封装得很好，参数就少很多。最后结果就是使用起来，其实更方便。</li>
</ul>
<h3><span id="代码上比较">代码上比较</span></h3><p>用TensorFlow写一个卷积层,第二层为例：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#第二层卷积层</span></span><br><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">"conv2"</span>) <span class="keyword">as</span> scope:</span><br><span class="line">    <span class="comment">#初始化权重</span></span><br><span class="line">    kernel2 = tf.Variable(tf.truncated_normal([<span class="number">5</span>,<span class="number">5</span>,<span class="number">64</span>,<span class="number">192</span>],dtype=tf.float32,stddev=<span class="number">0.1</span>)</span><br><span class="line">                          ,name=<span class="string">"weights"</span>)</span><br><span class="line">    conv = tf.nn.conv2d(pool1,kernel2,[<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>],padding=<span class="string">"SAME"</span>)</span><br><span class="line">    <span class="comment">#初始化偏置</span></span><br><span class="line">    biases = tf.Variable(tf.constant(<span class="number">0</span>,dtype=tf.float32,shape=[<span class="number">192</span>])</span><br><span class="line">                         ,trainable=<span class="literal">True</span>,name=<span class="string">"biases"</span>)</span><br><span class="line">    bias = tf.nn.bias_add(conv,biases)</span><br><span class="line">    <span class="comment">#RELU激活</span></span><br><span class="line">    conv2 = tf.nn.relu(bias,name=scope)</span><br><span class="line">    print_tensor_info(conv2)</span><br><span class="line">    parameters += [kernel2,biases]</span><br><span class="line">    <span class="comment">#LRN</span></span><br><span class="line">    lrn2 = tf.nn.lrn(conv2,<span class="number">4</span>,<span class="number">1.0</span>,alpha=<span class="number">1e-3</span>/<span class="number">9</span>,beta=<span class="number">0.75</span>,name=<span class="string">"lrn2"</span>)</span><br><span class="line">    <span class="comment">#最大池化</span></span><br><span class="line">    pool2 = tf.nn.max_pool(lrn2,[<span class="number">1</span>,<span class="number">3</span>,<span class="number">3</span>,<span class="number">1</span>],[<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>,<span class="number">1</span>],padding=<span class="string">"VALID"</span>,name=<span class="string">"pool2"</span>)</span><br><span class="line">    print_tensor_info(pool2)</span><br></pre></td></tr></table></figure></p>
<ul>
<li>每层都命名，这可能对可视化调试有些帮助，但是在网络逐渐变深的现在意义不大。</li>
<li>偏置和卷积核都用tf.Variable设置的变量，而且变量还是多，繁琐</li>
</ul>
<p>同样用pytorch写第二个层，就可以是<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">nn.Conv2d(<span class="number">64</span>, <span class="number">192</span>, <span class="number">5</span>, <span class="number">1</span>, <span class="number">2</span>),</span><br><span class="line">nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line">nn.MaxPool2d(<span class="number">3</span>, <span class="number">2</span>, <span class="number">0</span>),</span><br></pre></td></tr></table></figure></p>
<p>这写在nn.Sequential函数里面，会按序传播的。补一句解释：inplace为True，将会改变输入的数据 ，否则不会改变原输入，只会产生新的输出。是用于反向传播的。<br>最后说一句，pytorch做迁移学习是真方便</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/child/2019/07/03/AlexNet分类图片全纪录/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Allent Dan">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Allent's Blogs">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/07/03/AlexNet分类图片全纪录/" itemprop="url">AlexNet分类图片全纪录</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-07-03T14:20:54+08:00">
                2019-07-03
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1><span id="alexnet分类图片全纪录">AlexNet分类图片全纪录</span></h1><p>###背景</p>
<ul>
<li>因为工作需要，之前用谷歌网络InceptionV3虽然分类图片成功，并且效果也很好，但是因为谷歌网络是并行网络，说是22层网络，实际上有152层，在项目中表现为：准确率很高，但是CPU处理预测一幅图片需要0.7s，耗时较多。</li>
<li>考虑到AlexNet是只有8层的轻量级网络，也比较经典，尝试使用分类。事实上，使用AlexNet做迁移学习目前是非常少的，之前深度学习开始火的时候，倒是比较多，因为当时受限于算力，所以还是有很多人做了，但是也都是基于Caffe</li>
<li>这次，在算力已经大力发展的现在，用AlexNet做迁移学习意义不大。因此，直接用AlexNet做分类任务</li>
</ul>
<p><img src="https://www.mdpi.com/remotesensing/remotesensing-09-00848/article_deploy/html/images/remotesensing-09-00848-g003.png" alt="AlexNet"></p>
<h1><span id="解读alexnet">解读AlexNet</span></h1><p>AlexNet的解读已经非常多，贴个<a href="https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf" target="_blank" rel="noopener">原文链接</a>吧，然后贴个中英文对照版的<a href="https://www.jianshu.com/p/ea922866e3be" target="_blank" rel="noopener">博客</a>.下面是一些公认的AlexNet所做的贡献：</p>
<ul>
<li>alexnet中使用relu作为cnn的激活函数，验证效果远远好于sigmoid，解决了网络较深时的梯度弥散问题，并且加快了训练速度，虽然很早relu激活函数就存在了，但是alexnet成功的把它发扬光大。</li>
<li>训练时使用dropout来避免模型过拟合，dropout同样是已存在的技术，但是在alexnet验证了它的有效性，虽然之后有了BN之后一般不再使用dropout了</li>
<li>使用最大池化，避免了平均池化的模糊效果（突出重点特征）</li>
<li>提出了LRN层，对局部神经元的活动创建竞争机制，使得其中响应较大的值变得相对更大，并抑制其他较小的神经元，增强了模型的泛化能力</li>
<li>基于GPU使用CUDA加速神经网络的训练</li>
</ul>
<p>#用TensorFlow实现AlexNet网络<br>首先，感谢这位前辈的<a href="https://blog.csdn.net/missayaaa/article/details/79119839" target="_blank" rel="noopener">博客</a>，基本代码都是来自于他，然后做了稍许改变。里面的注释也都很详细，可以根据自己的需求来修改。</p>
<h1><span id="重点内容-调参">重点内容-调参</span></h1><p>我是做二分类任务，一类NG图片和二类OK图片各750张左右。即使AlexNet自身已经做了dropout防止过拟合，实际上和使用Inception做迁移学习比，AlexNet仍然存在着过拟合的问题。从头开始做二分类任务表现：为训练集上，batchSize设置8的时候，训练最后在训练集的准确率基本都是100%（8个里面对8个），但是在测试集上，只有90%的正确率。为此，我做了以下尝试来提高准确率：</p>
<ul>
<li>增加训练次数，调整batchSize大小，最后表现如下:<div><br><img src="https://raw.githubusercontent.com/AllentDan/PedestrianDetection/master/AlexNetImage/precision.PNG" alt="增加次数"><br></div></li>
<li>增加其他种类的图片，提高模型的泛化能力，增加两类图片，guitar，motorbike各五百张，这样训练次数增加到8000次，批次大小8，测试结果出乎意料地提高很多，达到97.9%：<div><br><img src="https://raw.githubusercontent.com/AllentDan/PedestrianDetection/master/AlexNetImage/%E5%8A%A0%E7%B1%BB%E5%88%AB%E5%9B%BE%E7%89%87%E5%90%8Eprecision.PNG" alt="增加种类"><br></div></li>
<li>增加OK和NG的训练样本个数，到各1200张图片，训练次数到40000，批次大小设置为2，最后预测结果准确率95.8%<div><br><img src="https://raw.githubusercontent.com/AllentDan/PedestrianDetection/master/AlexNetImage/40000EpochesWIth2BatchSize.PNG" alt="增加训练样本"><br></div></li>
<li>再次增加图片种类，这次添加flowers，animal和airplane类别，共训练7类，即使是用AlexNet迁移学习，也只不过是先在cifar-10数据集上先分类了10类而已，基本差别不大，通过多次调整批次大小，增减训练周期，得到模型。但是最终结果，准确率也只有97.9%不再增加。<div><br><img src="https://raw.githubusercontent.com/AllentDan/PedestrianDetection/master/AlexNetImage/final.PNG" alt="增加训练样本"><br></div>

</li>
</ul>
<h1><span id="结论">结论</span></h1><ul>
<li>改变批次和增多训练次数可提高准确率，前者一般靠运气</li>
<li>网络从头开始训练而非迁移学习的话，一般会存在过拟合，这是因为网络结构参数多于预测分类所需要的参数，这时可以通过增加样本类别提高泛化能力</li>
<li>AlexNet用于图片分类还是有很大的局限性，本身全连接层较多，容易出现过拟合。另外网络只有8层，不够深，一般层数越多效果越好，所以分类能力有限</li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/child/2019/07/03/python训练pb模型文件，C-使用模型预测生成dll，C-调用dll/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Allent Dan">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Allent's Blogs">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/07/03/python训练pb模型文件，C-使用模型预测生成dll，C-调用dll/" itemprop="url">python训练pb模型文件，C++使用模型预测生成dll，C#调用dll</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-07-03T14:20:10+08:00">
                2019-07-03
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1><span id="python训练pb模型文件c使用模型预测生成dllc调用dll">python训练pb模型文件，C++使用模型预测生成dll，C#调用dll</span></h1><p>###环境</p>
<ul>
<li>Anaconda+python3.6+Tensorflow-gpu 生成静态模型，也就是.pb模型</li>
<li>VS2017+TensorFlow C++API+OpenCV4.0 预测模型，打包成dll</li>
<li>具体C#版本没测，但是2013是失败了，2017成功调用dll</li>
</ul>
<p><img src="https://cdn-images-1.medium.com/max/1600/1*IN1lRBQQ8jW70J_nBAjxfw.png" alt="Incpetion"></p>
<h1><span id="inception-v3迁移学习">Inception V3迁移学习</span></h1><p>谷歌网络，在14年拿下当年imageNet分类冠军，深度只有22层，但是很胖，有多个并行网络，总共加起来有152层。Inception网络的迁移学习，之前的博客中已经提到，也给出了当时学习时候的视频。可以在前面的<a href="https://allentdan.github.io/2019/05/10/%E7%94%A8InceptionV3%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%E8%BF%9B%E8%A1%8C%E5%AE%A2%E6%B5%81%E6%A3%80%E6%B5%8B/" target="_blank" rel="noopener">博客</a>中看。</p>
<p>用该网络迁移学习，做二分类任务。分类焊点，检测出有没有焊点，分为没有焊点的NG类和有焊点的OK类。</p>
<p>#C++使用模型预测生成dll</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/child/2019/06/08/用YOLO3数人头/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Allent Dan">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Allent's Blogs">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/06/08/用YOLO3数人头/" itemprop="url">用yolo v3训练自己的模型并进行客流检测</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-06-08T19:26:19+08:00">
                2019-06-08
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h3><span id="项目背景">项目背景</span></h3><ul>
<li><p>前面我分别用谷歌网络Inception和svm+slidemask进行过客流检测的尝试，效果都一般，这个是由于Inception模型迁移学习后太大，而svm训练本身不容易，而且不稳定，容易误检测。这些都可以归因于two stages做目标检测的缺陷</p>
</li>
<li><p>前面几次的尝试我也有陆续做了部分记录，可以看看，当然效果都挺感人</p>
<p><a href="https://allentdan.github.io/2019/05/15/试用SVM-slideMask做客流检测-失败/" target="_blank" rel="noopener">svm+slideMask检测客流</a></p>
<p><a href="https://allentdan.github.io/2019/05/10/用InceptionV3迁移学习进行客流检测/" target="_blank" rel="noopener">Inception V3进行客流检测</a></p>
</li>
<li><p>本次 keras yolo检测主要参考有<a href="https://blog.csdn.net/weixin_43472830/article/details/88320099" target="_blank" rel="noopener">YOLO基础教程（四）：yolo v3 训练自己的数据集</a>，<a href="https://blog.csdn.net/Patrick_Lxc/article/details/80615433" target="_blank" rel="noopener">Keras/Tensorflow+python+yolo3训练自己的数据集</a>以及<a href="https://blog.csdn.net/jesse_mx/article/details/53606897" target="_blank" rel="noopener">样本标注工具，图片标注工具LabelImg使用教程</a>。其他还有很多零零散散的，包括一些视频和yolo官方网站，就不一一列举了。</p>
</li>
</ul>
<h1><span id="keras-yolo客流量检测md">keras yolo客流量检测.md</span></h1><div align="center"><br><img src="https://github.com/AllentDan/PedestrianDetection/blob/master/yoloImage/result.png?raw=true" alt="result.jpg"><br></div>

<p><strong>目录 (Table of Contents)</strong></p>
<p>[TOCM]</p>
<p>[TOC]</p>
<h1><span id="下载使用yolo官方权重文件测试">下载使用yolo官方权重文件测试</span></h1><h2><span id="yolo介绍">yolo介绍</span></h2><p>不多说，想知道yolo检测原理的直接看这篇<a href="https://www.jianshu.com/p/13ec2aa50c12" target="_blank" rel="noopener">YOLO文章详细解读</a>。yolo是美国某大学的研究生弄出来的一个端到端(end to end)网络，还上了TED做演讲，看看人家研究生，再看看我们哈哈哈。所谓端到端，我理解的在目标检测中也就是不用先分类，再切割图片识别，而是直接对图片预测目标位置和大小，也就是将two stages变成one stage检测。</p>
<h2><span id="配置环境">配置环境</span></h2><p>大家可以参考csdn博主<a href="https://me.csdn.net/weixin_43472830" target="_blank" rel="noopener">王氏小明</a>的<a href="https://blog.csdn.net/weixin_43472830/article/details/88022869" target="_blank" rel="noopener">YOLO基础教程（一）：Python环境搭建与测试</a>，也可以参考我前面的博客</p>
<h2><span id="直接yolo检测客流看看效果">直接yolo检测客流看看效果</span></h2><p>不得不说，即使是高清的动物世界视频，yolo官方权重检测出的效果其实也还可以，但是还是有许多误检测。更不要说老师给的如上图所示的av画质视频效果了。当然，yolo检测的速度还是很快的，双GTX 1080 ti gpu下可以达到30fps。从输出看，它的bounding box也比two stages的滑动窗口更能准确表示物体的位置和大小。</p>
<h1><span id="用yolo训练自己的权重文件">用YOLO训练自己的权重文件</span></h1><h2><span id="先做样本集">先做样本集</span></h2><p>可以说，训练深度网络，大概是三分之一的时间做样本，三分之一的时间敲代码，还有三分之一的时间调参数。制作样本，因为班里老师给的是视频，而yolo使用的标注工具是读图片的，所以省去自己写脚本弄，需要先改成每帧或几十帧获取一幅图片放到一个文件夹里面。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">//代码落公司电脑了，很简单，百度“python 视频转图片”然后自己调调就好了</span><br></pre></td></tr></table></figure>
<h1><span id="labelimage标注">labelImage标注</span></h1><p>按照项目背景中的参考博客，创建好文件夹以后(其实里面部分文件夹似乎没有用，但是你还是按照他的来吧)，使用工具LabelImg，里面给的链接已经失效，所以我又在项目背景中列了另外一个，是labelImage的源码，它会教你使用。</p>
<p>在labelImage工具图形界面三步走，标注玩完一百幅图片大概需要半个到一个小时。请尽量将尽可能多的不同的图片放进去标注。你可以选择就标注一个类别head，也可以多加几类其他的，如果你内存够的话。</p>
<h2><span id="多建一个分类放负样本">多建一个分类放负样本</span></h2><p>嘣~结果非常好，暂时就先不贴图了，后面再更，包括引入滑动窗口对整张图片做识别。</p>
<p>………………………..</p>
<p>好了，2019年5月13日下午，我又回来了。像我之前所说，同时截出正负样本进行训练，然后用滑动窗口复制出许许多多的测试图放入网络中测试。</p>
<h1><span id="testpy生成训练时候的测试集和训练集">test.py生成训练时候的测试集和训练集</span></h1><h2><span id="testpy">test.py</span></h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"> </span><br><span class="line">trainval_percent = <span class="number">0.1</span></span><br><span class="line">train_percent = <span class="number">0.9</span></span><br><span class="line">xmlfilepath = <span class="string">'Annotations'</span></span><br><span class="line">txtsavepath = <span class="string">'ImageSets\Main'</span></span><br><span class="line">total_xml = os.listdir(xmlfilepath)</span><br><span class="line"> </span><br><span class="line">num = len(total_xml)</span><br><span class="line">list = range(num)</span><br><span class="line">tv = int(num * trainval_percent)</span><br><span class="line">tr = int(tv * train_percent)</span><br><span class="line">trainval = random.sample(list, tv)</span><br><span class="line">train = random.sample(trainval, tr)</span><br><span class="line"> </span><br><span class="line">ftrainval = open(<span class="string">'ImageSets/Main/trainval.txt'</span>, <span class="string">'w'</span>)</span><br><span class="line">ftest = open(<span class="string">'ImageSets/Main/test.txt'</span>, <span class="string">'w'</span>)</span><br><span class="line">ftrain = open(<span class="string">'ImageSets/Main/train.txt'</span>, <span class="string">'w'</span>)</span><br><span class="line">fval = open(<span class="string">'ImageSets/Main/val.txt'</span>, <span class="string">'w'</span>)</span><br><span class="line"> </span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> list:</span><br><span class="line">    name = total_xml[i][:<span class="number">-4</span>] + <span class="string">'\n'</span></span><br><span class="line">    <span class="keyword">if</span> i <span class="keyword">in</span> trainval:</span><br><span class="line">        ftrainval.write(name)</span><br><span class="line">        <span class="keyword">if</span> i <span class="keyword">in</span> train:</span><br><span class="line">            ftest.write(name)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            fval.write(name)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        ftrain.write(name)</span><br><span class="line"> </span><br><span class="line">ftrainval.close()</span><br><span class="line">ftrain.close()</span><br><span class="line">fval.close()</span><br><span class="line">ftest.close()</span><br><span class="line">--------------------- </span><br><span class="line">作者：王氏小明 </span><br><span class="line">来源：CSDN </span><br><span class="line">原文：https://blog.csdn.net/weixin_43472830/article/details/<span class="number">88320099</span> </span><br><span class="line">不要脸地直接拿来用了</span><br></pre></td></tr></table></figure>
<h2><span id="一步步按教程来">一步步按教程来</span></h2><p>说一下你可能遇到的问题，只有CPU的话直接加参考博客里os设置，我的是GPU，但是依然有问题。训练时候，第一个周期训练有时候是内存超了，然后黑屏或者闪退，这时候你可能需要减少你的训练集大小。改好以后，第一个周期依然很长时间，我第一次大概要20~40分钟，因为里面涉及到读取图片输入问题。然后后面每个周期就大概十几秒，每个step大概就几十ms。</p>
<h1><span id="我的权重文件">我的权重文件</span></h1><p>最后将我自己的权重文件放上来，因为训练时候，输入的样本就100张，然后训练了大概30个周期就收敛完了，loss降到20几，所以效果一般。另外，预测时候的score和IOU设置也不够好，所以最后效果，可以在前面看到，还是有很多问题的。但是总体来说比前面的svm和Inception好很多了。</p>
<p>我训练的权重文件在<a href="https://pan.baidu.com/s/178IL5IL3s-e0fafZg0kuJg" target="_blank" rel="noopener">这</a>，密码是：b2p5</p>
<p>链接失效的话，可以在我blibli账号下留言哈哈。</p>
<p>我的yolo预测文件，使用时候根据需要改变score下限和IOU大小，然后使用detect_video函数或者detect_img函数就好，找出你满意的。步骤大概是：</p>
<p>1 终端python yolo.py或者在ide中打开运行</p>
<p>2 yolo=YOLO()</p>
<p>3 设置对应输入输出路径，调用detect_video函数</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">Class definition of YOLO_v3 style detection model on image and video</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> colorsys</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> timeit <span class="keyword">import</span> default_timer <span class="keyword">as</span> timer</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> backend <span class="keyword">as</span> K</span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> load_model</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Input</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image, ImageFont, ImageDraw</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> yolo3.model <span class="keyword">import</span> yolo_eval, yolo_body, tiny_yolo_body</span><br><span class="line"><span class="keyword">from</span> yolo3.utils <span class="keyword">import</span> letterbox_image</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> keras.utils <span class="keyword">import</span> multi_gpu_model</span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">YOLO</span><span class="params">(object)</span>:</span></span><br><span class="line">    _defaults = &#123;</span><br><span class="line">        <span class="string">"model_path"</span>: <span class="string">'logs/000/trained_weights_stage_1.h5'</span>,</span><br><span class="line">        <span class="string">"anchors_path"</span>: <span class="string">'model_data/yolo_anchors.txt'</span>,</span><br><span class="line">        <span class="string">"classes_path"</span>: <span class="string">'model_data/coco_classes.txt'</span>,</span><br><span class="line">        <span class="string">"score"</span> : <span class="number">0.15</span>,</span><br><span class="line">        <span class="string">"iou"</span> : <span class="number">0.3</span>,</span><br><span class="line">        <span class="string">"model_image_size"</span> : (<span class="number">416</span>, <span class="number">416</span>),</span><br><span class="line">        <span class="string">"gpu_num"</span> : <span class="number">1</span>,</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">    @classmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_defaults</span><span class="params">(cls, n)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> n <span class="keyword">in</span> cls._defaults:</span><br><span class="line">            <span class="keyword">return</span> cls._defaults[n]</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="string">"Unrecognized attribute name '"</span> + n + <span class="string">"'"</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, **kwargs)</span>:</span></span><br><span class="line">        self.__dict__.update(self._defaults) <span class="comment"># set up default values</span></span><br><span class="line">        self.__dict__.update(kwargs) <span class="comment"># and update with user overrides</span></span><br><span class="line">        self.class_names = self._get_class()</span><br><span class="line">        self.anchors = self._get_anchors()</span><br><span class="line">        self.sess = K.get_session()</span><br><span class="line">        self.boxes, self.scores, self.classes = self.generate()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_get_class</span><span class="params">(self)</span>:</span></span><br><span class="line">        classes_path = os.path.expanduser(self.classes_path)</span><br><span class="line">        <span class="keyword">with</span> open(classes_path) <span class="keyword">as</span> f:</span><br><span class="line">            class_names = f.readlines()</span><br><span class="line">        class_names = [c.strip() <span class="keyword">for</span> c <span class="keyword">in</span> class_names]</span><br><span class="line">        <span class="keyword">return</span> class_names</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_get_anchors</span><span class="params">(self)</span>:</span></span><br><span class="line">        anchors_path = os.path.expanduser(self.anchors_path)</span><br><span class="line">        <span class="keyword">with</span> open(anchors_path) <span class="keyword">as</span> f:</span><br><span class="line">            anchors = f.readline()</span><br><span class="line">        anchors = [float(x) <span class="keyword">for</span> x <span class="keyword">in</span> anchors.split(<span class="string">','</span>)]</span><br><span class="line">        <span class="keyword">return</span> np.array(anchors).reshape(<span class="number">-1</span>, <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">generate</span><span class="params">(self)</span>:</span></span><br><span class="line">        model_path = os.path.expanduser(self.model_path)</span><br><span class="line">        <span class="keyword">assert</span> model_path.endswith(<span class="string">'.h5'</span>), <span class="string">'Keras model or weights must be a .h5 file.'</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># Load model, or construct model and load weights.</span></span><br><span class="line">        num_anchors = len(self.anchors)</span><br><span class="line">        num_classes = len(self.class_names)</span><br><span class="line">        is_tiny_version = num_anchors==<span class="number">6</span> <span class="comment"># default setting</span></span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            self.yolo_model = load_model(model_path, compile=<span class="literal">False</span>)</span><br><span class="line">        <span class="keyword">except</span>:</span><br><span class="line">            self.yolo_model = tiny_yolo_body(Input(shape=(<span class="literal">None</span>,<span class="literal">None</span>,<span class="number">3</span>)), num_anchors//<span class="number">2</span>, num_classes) \</span><br><span class="line">                <span class="keyword">if</span> is_tiny_version <span class="keyword">else</span> yolo_body(Input(shape=(<span class="literal">None</span>,<span class="literal">None</span>,<span class="number">3</span>)), num_anchors//<span class="number">3</span>, num_classes)</span><br><span class="line">            self.yolo_model.load_weights(self.model_path) <span class="comment"># make sure model, anchors and classes match</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">assert</span> self.yolo_model.layers[<span class="number">-1</span>].output_shape[<span class="number">-1</span>] == \</span><br><span class="line">                num_anchors/len(self.yolo_model.output) * (num_classes + <span class="number">5</span>), \</span><br><span class="line">                <span class="string">'Mismatch between model and given anchor and class sizes'</span></span><br><span class="line"></span><br><span class="line">        print(<span class="string">'&#123;&#125; model, anchors, and classes loaded.'</span>.format(model_path))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Generate colors for drawing bounding boxes.</span></span><br><span class="line">        hsv_tuples = [(x / len(self.class_names), <span class="number">1.</span>, <span class="number">1.</span>)</span><br><span class="line">                      <span class="keyword">for</span> x <span class="keyword">in</span> range(len(self.class_names))]</span><br><span class="line">        self.colors = list(map(<span class="keyword">lambda</span> x: colorsys.hsv_to_rgb(*x), hsv_tuples))</span><br><span class="line">        self.colors = list(</span><br><span class="line">            map(<span class="keyword">lambda</span> x: (int(x[<span class="number">0</span>] * <span class="number">255</span>), int(x[<span class="number">1</span>] * <span class="number">255</span>), int(x[<span class="number">2</span>] * <span class="number">255</span>)),</span><br><span class="line">                self.colors))</span><br><span class="line">        np.random.seed(<span class="number">10101</span>)  <span class="comment"># Fixed seed for consistent colors across runs.</span></span><br><span class="line">        np.random.shuffle(self.colors)  <span class="comment"># Shuffle colors to decorrelate adjacent classes.</span></span><br><span class="line">        np.random.seed(<span class="literal">None</span>)  <span class="comment"># Reset seed to default.</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># Generate output tensor targets for filtered bounding boxes.</span></span><br><span class="line">        self.input_image_shape = K.placeholder(shape=(<span class="number">2</span>, ))</span><br><span class="line">        <span class="keyword">if</span> self.gpu_num&gt;=<span class="number">2</span>:</span><br><span class="line">            self.yolo_model = multi_gpu_model(self.yolo_model, gpus=self.gpu_num)</span><br><span class="line">        boxes, scores, classes = yolo_eval(self.yolo_model.output, self.anchors,</span><br><span class="line">                len(self.class_names), self.input_image_shape,</span><br><span class="line">                score_threshold=self.score, iou_threshold=self.iou)</span><br><span class="line">        <span class="keyword">return</span> boxes, scores, classes</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">detect_image</span><span class="params">(self, image)</span>:</span></span><br><span class="line">        start = timer()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> self.model_image_size != (<span class="literal">None</span>, <span class="literal">None</span>):</span><br><span class="line">            <span class="keyword">assert</span> self.model_image_size[<span class="number">0</span>]%<span class="number">32</span> == <span class="number">0</span>, <span class="string">'Multiples of 32 required'</span></span><br><span class="line">            <span class="keyword">assert</span> self.model_image_size[<span class="number">1</span>]%<span class="number">32</span> == <span class="number">0</span>, <span class="string">'Multiples of 32 required'</span></span><br><span class="line">            boxed_image = letterbox_image(image, tuple(reversed(self.model_image_size)))</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            new_image_size = (image.width - (image.width % <span class="number">32</span>),</span><br><span class="line">                              image.height - (image.height % <span class="number">32</span>))</span><br><span class="line">            boxed_image = letterbox_image(image, new_image_size)</span><br><span class="line">        image_data = np.array(boxed_image, dtype=<span class="string">'float32'</span>)</span><br><span class="line"></span><br><span class="line">        print(image_data.shape)</span><br><span class="line">        image_data /= <span class="number">255.</span></span><br><span class="line">        image_data = np.expand_dims(image_data, <span class="number">0</span>)  <span class="comment"># Add batch dimension.</span></span><br><span class="line"></span><br><span class="line">        out_boxes, out_scores, out_classes = self.sess.run(</span><br><span class="line">            [self.boxes, self.scores, self.classes],</span><br><span class="line">            feed_dict=&#123;</span><br><span class="line">                self.yolo_model.input: image_data,</span><br><span class="line">                self.input_image_shape: [image.size[<span class="number">1</span>], image.size[<span class="number">0</span>]],</span><br><span class="line">                K.learning_phase(): <span class="number">0</span></span><br><span class="line">            &#125;)</span><br><span class="line"></span><br><span class="line">        print(<span class="string">'Found &#123;&#125; boxes for &#123;&#125;'</span>.format(len(out_boxes), <span class="string">'img'</span>))</span><br><span class="line"></span><br><span class="line">        font = ImageFont.truetype(font=<span class="string">'font/FiraMono-Medium.otf'</span>,</span><br><span class="line">                    size=np.floor(<span class="number">3e-2</span> * image.size[<span class="number">1</span>] + <span class="number">0.5</span>).astype(<span class="string">'int32'</span>))</span><br><span class="line">        thickness = (image.size[<span class="number">0</span>] + image.size[<span class="number">1</span>]) // <span class="number">300</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> i, c <span class="keyword">in</span> reversed(list(enumerate(out_classes))):</span><br><span class="line">            predicted_class = self.class_names[c]</span><br><span class="line">            box = out_boxes[i]</span><br><span class="line">            score = out_scores[i]</span><br><span class="line"></span><br><span class="line">            label = <span class="string">'&#123;&#125; &#123;:.2f&#125;'</span>.format(predicted_class, score)</span><br><span class="line">            draw = ImageDraw.Draw(image)</span><br><span class="line">            label_size = draw.textsize(label, font)</span><br><span class="line"></span><br><span class="line">            top, left, bottom, right = box</span><br><span class="line">            top = max(<span class="number">0</span>, np.floor(top + <span class="number">0.5</span>).astype(<span class="string">'int32'</span>))</span><br><span class="line">            left = max(<span class="number">0</span>, np.floor(left + <span class="number">0.5</span>).astype(<span class="string">'int32'</span>))</span><br><span class="line">            bottom = min(image.size[<span class="number">1</span>], np.floor(bottom + <span class="number">0.5</span>).astype(<span class="string">'int32'</span>))</span><br><span class="line">            right = min(image.size[<span class="number">0</span>], np.floor(right + <span class="number">0.5</span>).astype(<span class="string">'int32'</span>))</span><br><span class="line">            print(label, (left, top), (right, bottom))</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> top - label_size[<span class="number">1</span>] &gt;= <span class="number">0</span>:</span><br><span class="line">                text_origin = np.array([left, top - label_size[<span class="number">1</span>]])</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                text_origin = np.array([left, top + <span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">            <span class="comment"># My kingdom for a good redistributable image drawing library.</span></span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> range(thickness):</span><br><span class="line">                draw.rectangle(</span><br><span class="line">                    [left + i, top + i, right - i, bottom - i],</span><br><span class="line">                    outline=self.colors[c])</span><br><span class="line">            draw.rectangle(</span><br><span class="line">                [tuple(text_origin), tuple(text_origin + label_size)],</span><br><span class="line">                fill=self.colors[c])</span><br><span class="line">            draw.text(text_origin, label, fill=(<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>), font=font)</span><br><span class="line">            <span class="keyword">del</span> draw</span><br><span class="line">        draw = ImageDraw.Draw(image)</span><br><span class="line">        draw.text((<span class="number">3</span>,<span class="number">15</span>),<span class="string">"All:"</span>+str(len(out_boxes)),(<span class="number">255</span>,<span class="number">0</span>,<span class="number">0</span>))</span><br><span class="line">        <span class="keyword">del</span> draw</span><br><span class="line">        end = timer()</span><br><span class="line">        print(end - start)</span><br><span class="line">        <span class="keyword">return</span> image</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">close_session</span><span class="params">(self)</span>:</span></span><br><span class="line">        self.sess.close()</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">detect_video</span><span class="params">(yolo, video_path, output_path=<span class="string">""</span>)</span>:</span></span><br><span class="line"><span class="comment">#    import cv2</span></span><br><span class="line">    vid = cv2.VideoCapture(video_path)</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> vid.isOpened():</span><br><span class="line">        cv2.destroyAllWindows()</span><br><span class="line">        <span class="keyword">raise</span> IOError(<span class="string">"Couldn't open webcam or video"</span>)</span><br><span class="line">    video_FourCC    = int(vid.get(cv2.CAP_PROP_FOURCC))</span><br><span class="line">    video_fps       = vid.get(cv2.CAP_PROP_FPS)</span><br><span class="line">    video_size      = (int(vid.get(cv2.CAP_PROP_FRAME_WIDTH)),</span><br><span class="line">                        int(vid.get(cv2.CAP_PROP_FRAME_HEIGHT)))</span><br><span class="line">    isOutput = <span class="literal">True</span> <span class="keyword">if</span> output_path != <span class="string">""</span> <span class="keyword">else</span> <span class="literal">False</span></span><br><span class="line">    <span class="keyword">if</span> isOutput:</span><br><span class="line">        print(<span class="string">"!!! TYPE:"</span>, type(output_path), type(video_FourCC), type(video_fps), type(video_size))</span><br><span class="line">        out = cv2.VideoWriter(output_path, video_FourCC, video_fps, video_size)</span><br><span class="line">    accum_time = <span class="number">0</span></span><br><span class="line">    curr_fps = <span class="number">0</span></span><br><span class="line">    fps = <span class="string">"FPS: ??"</span></span><br><span class="line">    prev_time = timer()</span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">        return_value, frame = vid.read()</span><br><span class="line">        image = Image.fromarray(frame)</span><br><span class="line">        image = yolo.detect_image(image)</span><br><span class="line">        result = np.asarray(image)</span><br><span class="line">        curr_time = timer()</span><br><span class="line">        exec_time = curr_time - prev_time</span><br><span class="line">        prev_time = curr_time</span><br><span class="line">        accum_time = accum_time + exec_time</span><br><span class="line">        curr_fps = curr_fps + <span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> accum_time &gt; <span class="number">1</span>:</span><br><span class="line">            accum_time = accum_time - <span class="number">1</span></span><br><span class="line">            fps = <span class="string">"FPS: "</span> + str(curr_fps)</span><br><span class="line">            curr_fps = <span class="number">0</span></span><br><span class="line"><span class="comment">#        cv2.putText(result, text=fps, org=(3, 15), fontFace=cv2.FONT_HERSHEY_SIMPLEX,</span></span><br><span class="line"><span class="comment">#                    fontScale=0.50, color=(255, 0, 0), thickness=2)</span></span><br><span class="line">        cv2.namedWindow(<span class="string">"result"</span>, cv2.WINDOW_NORMAL)</span><br><span class="line">        cv2.imshow(<span class="string">"result"</span>, result)</span><br><span class="line">        <span class="keyword">if</span> isOutput:</span><br><span class="line">            out.write(result)</span><br><span class="line">        <span class="keyword">if</span> cv2.waitKey(<span class="number">1</span>) &amp; <span class="number">0xFF</span> == ord(<span class="string">'q'</span>):</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">    yolo.close_session()</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">detect_img</span><span class="params">(yolo)</span>:</span></span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">        img = input(<span class="string">'Input image filename:'</span>)</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            image = Image.open(img)</span><br><span class="line">        <span class="keyword">except</span>:</span><br><span class="line">            print(<span class="string">'Open Error! Try again!'</span>)</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            r_image = yolo.detect_image(image)</span><br><span class="line">            r_image.show()</span><br><span class="line">    yolo.close_session()</span><br></pre></td></tr></table></figure>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/child/2019/05/15/试用SVM-slideMask做客流检测-失败/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Allent Dan">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Allent's Blogs">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/05/15/试用SVM-slideMask做客流检测-失败/" itemprop="url">试用SVM+HOG+SlideWindows做客流检测(成功)</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-05-15T16:18:26+08:00">
                2019-05-15
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h3><span id="项目背景">项目背景</span></h3><ul>
<li>刚刚用谷歌的Inception V3尝试检测行人，效果一般，想看的点<a href="[https://allentdan.github.io/2019/05/10/%E7%94%A8InceptionV3%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%E8%BF%9B%E8%A1%8C%E5%AE%A2%E6%B5%81%E6%A3%80%E6%B5%8B/](https://allentdan.github.io/2019/05/10/用InceptionV3迁移学习进行客流检测/">这</a>)</li>
<li>不死心，还想用传统方法挣扎下，因为传统方法计算很快，就尝试用HOG+SVM训练自己的样本集，再进行测试，主要参考<a href="https://blog.csdn.net/oxuzhenyi/article/details/72818404" target="_blank" rel="noopener">这篇博客</a>，但是不得不说，该博客用的python2，跑在Python3里面问题相当的多，代码也不知道从哪搬运过来的，被中英混合着注释各种改，但是初始代码想必是官方给的example</li>
<li>如果想直接看yolo检测，可以左转出门，下方有，后面更</li>
</ul>
<div align="center"><br><img src="https://github.com/AllentDan/PedestrianDetection/raw/master/images/threeePeople.jpg" alt="cover"><br></div>


<p>[TOC]</p>
<h1><span id="还原参考博客内容">还原参考博客内容</span></h1><h2><span id="下载修改">下载修改</span></h2><p>不多说，weget指令就是好，linux就是牛逼。但是Windows也不差，直接选中weget的目标url右键转到（不确定其他浏览器，谷歌chrome安装迅雷插件）就可以跳出迅雷下载了，完了用IDE打开，一堆错误，毕竟是篇远古博客了，而且涂改也是相当严重。不过大部分就是print问题，花点功夫的事情</p>
<h2><span id="修改统一图片尺寸">修改统一图片尺寸</span></h2><p>还是上篇博客弄好的样本集，只不过这次先统一尺寸，因为OpenCV的SVM需要读入图片是64*128，虽然最后训练也都是一维的1024向量。没啥多说的，直接po代码</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">from</span> os.path <span class="keyword">import</span> dirname, join, basename</span><br><span class="line"><span class="keyword">from</span> glob <span class="keyword">import</span> glob</span><br><span class="line"> </span><br><span class="line">num=<span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> fn <span class="keyword">in</span> glob(join(dirname(__file__)+<span class="string">'/nega'</span>,<span class="string">'*.jpg'</span>)):    <span class="comment">#获取位置的nega文件夹下所有的jpg图片，nega文件夹下面是我存放的所有负样本</span></span><br><span class="line">    print(fn)</span><br><span class="line">    img = cv2.imread(fn)</span><br><span class="line">    res=cv2.resize(img,(<span class="number">64</span>,<span class="number">128</span>),interpolation=cv2.INTER_AREA)<span class="comment">#线性插值并统一尺寸</span></span><br><span class="line">    cv2.imwrite(<span class="string">'E:\\Python\\SVM4Pedestrian\\nega_resized\\'</span>+str(num)+<span class="string">'.jpg'</span>,res)<span class="comment">#新建nega_resized文件夹，将所有处理后的图片写到该文件夹</span></span><br><span class="line">    num=num+<span class="number">1</span></span><br><span class="line"> </span><br><span class="line"><span class="keyword">print</span> (<span class="string">'all done!'</span>)</span><br></pre></td></tr></table></figure>
<h2><span id="trainpredictpy">train+predict.py</span></h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="comment">#from matplotlib import pyplot as plt</span></span><br><span class="line"><span class="keyword">from</span> os.path <span class="keyword">import</span> dirname, join, basename</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">from</span> glob <span class="keyword">import</span> glob</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">bin_n = <span class="number">16</span>*<span class="number">16</span> <span class="comment"># Number of bins</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">hog</span><span class="params">(img)</span>:</span></span><br><span class="line">    x_pixel,y_pixel=<span class="number">194</span>,<span class="number">259</span></span><br><span class="line">    gx = cv2.Sobel(img, cv2.CV_32F, <span class="number">1</span>, <span class="number">0</span>)</span><br><span class="line">    gy = cv2.Sobel(img, cv2.CV_32F, <span class="number">0</span>, <span class="number">1</span>)</span><br><span class="line">    mag, ang = cv2.cartToPolar(gx, gy)</span><br><span class="line">    bins = np.int32(bin_n*ang/(<span class="number">2</span>*np.pi))   </span><br><span class="line">    x_pixel_int=int(x_pixel/<span class="number">2</span>)</span><br><span class="line">    y_pixel_int=int(y_pixel/<span class="number">2</span>)</span><br><span class="line">    bin_cells = bins[:x_pixel_int,:y_pixel_int], bins[x_pixel_int:,:y_pixel_int], bins[:x_pixel_int,y_pixel_int:], bins[x_pixel_int:,y_pixel_int:]</span><br><span class="line">    mag_cells = mag[:x_pixel_int,:y_pixel_int], mag[x_pixel_int:,:y_pixel_int], mag[:x_pixel_int,y_pixel_int:], mag[x_pixel_int:,y_pixel_int:]</span><br><span class="line">    hists = [np.bincount(b.ravel(), m.ravel(), bin_n) <span class="keyword">for</span> b, m <span class="keyword">in</span> zip(bin_cells, mag_cells)]</span><br><span class="line">    hist = np.hstack(hists)     <span class="comment"># hist is a 64 bit vector</span></span><br><span class="line">    <span class="keyword">return</span> hist</span><br><span class="line"></span><br><span class="line">img=&#123;&#125;</span><br><span class="line">num=<span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> fn <span class="keyword">in</span> glob(join(dirname(__file__)+<span class="string">'/posi_resized'</span>, <span class="string">'*.jpg'</span>)):</span><br><span class="line">    img[num] = cv2.imread(fn,<span class="number">0</span>)<span class="comment">#参数加0，只读取黑白数据，去掉0，就是彩色读取。</span></span><br><span class="line"><span class="comment">#    print img[num].shape</span></span><br><span class="line">    num=num+<span class="number">1</span></span><br><span class="line">positive=num</span><br><span class="line"><span class="keyword">for</span> fn <span class="keyword">in</span> glob(join(dirname(__file__)+<span class="string">'/nega_resized'</span>, <span class="string">'*.jpg'</span>)):</span><br><span class="line">    img[num] = cv2.imread(fn,<span class="number">0</span>)<span class="comment">#参数加0，只读取黑白数据，去掉0，就是彩色读取。</span></span><br><span class="line"><span class="comment">#    print img[num].shape</span></span><br><span class="line">    num=num+<span class="number">1</span></span><br><span class="line"></span><br><span class="line">trainpic=[]</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> img:</span><br><span class="line"><span class="comment">#    print type(i)</span></span><br><span class="line">    trainpic.append(img[i])</span><br><span class="line"></span><br><span class="line"><span class="comment">#hogdata = [map(hog,img[i]) for i in img]</span></span><br><span class="line">hogdata=list(map(hog,trainpic))</span><br><span class="line">trainData = np.float32(hogdata).reshape(<span class="number">-1</span>,bin_n*<span class="number">4</span>)</span><br><span class="line">responses = np.int32(np.repeat(<span class="number">1.0</span>,trainData.shape[<span class="number">0</span>])[:,np.newaxis])</span><br><span class="line">responses[positive:trainData.shape[<span class="number">0</span>]]=<span class="number">-1.0</span></span><br><span class="line"><span class="comment">#print (type(trainData))</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">svm = cv2.ml.SVM_create() <span class="comment">#创建SVM model</span></span><br><span class="line"><span class="comment">#属性设置</span></span><br><span class="line">svm.setType(cv2.ml.SVM_C_SVC)</span><br><span class="line">svm.setKernel(cv2.ml.SVM_LINEAR)</span><br><span class="line">svm.setC(<span class="number">0.01</span>)</span><br><span class="line"><span class="comment">#训练</span></span><br><span class="line">result = svm.train(trainData,cv2.ml.ROW_SAMPLE,responses)</span><br><span class="line">svm.save(<span class="string">'svm_cat_data.dat'</span>)</span><br><span class="line"><span class="comment">######测试</span></span><br><span class="line">test_temp=[]</span><br><span class="line"><span class="keyword">for</span> fn <span class="keyword">in</span> glob(join(dirname(__file__)+<span class="string">'/predict_resized'</span>, <span class="string">'*.jpg'</span>)):</span><br><span class="line">    img=cv2.imread(fn,<span class="number">0</span>)<span class="comment">#参数加0，只读取黑白数据，去掉0，就是彩色读取。</span></span><br><span class="line">    test_temp.append(img)</span><br><span class="line">testdata=list(map(hog,test_temp))</span><br><span class="line">testData = np.float32(testdata).reshape(<span class="number">-1</span>,bin_n*<span class="number">4</span>)</span><br><span class="line">re=svm.predict(testData)</span><br></pre></td></tr></table></figure>
<h2><span id="报错修改">报错修改</span></h2><p>train.py跑通后，尝试测试下训练集里面的第一个，一般都会预测准确，不然SVM也不用混了。除去一些可以立马解决的小问题，主要问题其实就三个：</p>
<p>第一个是里面的map函数，会报错TypeError: float() argument must be a string or a number, not ‘map’，老版本Python可以没有问题，但是3以后的基本需要外面套个list()，参考<a href="https://blog.csdn.net/shangxiaqiusuo1/article/details/84336339" target="_blank" rel="noopener">这个大哥的方法</a>；</p>
<p>第二个就是集中在OpenCV更新后，SVM相关的函数都发生了变化，被移动到ml属性下面了，需要先调用ml再调用SVM，此外创建SVM和配置SVM都发生了变化；</p>
<p>第三个就是保存SVM模型后，调用模型文件预测会出问题，而且我没有解决，只好不保存，直接训练完后测试，最后直接和训练跑在一个py文件里面了。</p>
<h1><span id="svm分类结果">SVM分类结果</span></h1><p>非常心痛，测试了28个图片，错了三个，和神经网络跑出来准确率天差地别。可能原因其实很多，图片本身信息不够，区分度也不会好。SVM算法本身和神经网络准确率差别在那。不用做滑动窗口了，直接放弃，白瞎一下午功夫。</p>
<h1><span id="结论">结论</span></h1><p>可能先用CNN提取特征再用SVM分类识别会提高准确率，但是已经不想浪费精力了，直接yolo走起。</p>
<h1><span id="2019520更新">2019.5.20更新</span></h1><p>windows下使用yolo检测视频还是不容易，听说用GPU跑个几百张图片都得几天时间，样本集制作也是麻烦，想了想换了个svm工具，不再使用OpenCV自带的svm分类器分类训练。因为它自带的只能分类，不能给出分类的置信度，另外分类效果也很差劲。改用sklearn工具包里的svm分类器，就可以得到近似的置信度，然后可以在非极大值抑制中使用。效果见封面，不过调参是个大工程（玄学）</p>
<h2><span id="介绍下sklearn的svm">介绍下sklearn的SVM</span></h2><p>Scikit-learn is a free software machine learning library for the Python programming language. It features various classification, regression and clustering algorithms including support vector machines, …</p>
<p>上面是维基百科的一通blabla，反正就是Python的一个有用工具包。下面重点介绍下它的SVM，方法很简单：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> svm</span><br><span class="line"> </span><br><span class="line">X = [[<span class="number">0</span>, <span class="number">0</span>], [<span class="number">1</span>, <span class="number">1</span>], [<span class="number">1</span>, <span class="number">0</span>]]  <span class="comment">#样本 </span></span><br><span class="line">y = [<span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>]  <span class="comment"># 标签</span></span><br><span class="line">clf = svm.SVC()  <span class="comment"># 定义分类器</span></span><br><span class="line">clf.fit(X, y)  <span class="comment"># 训练</span></span><br><span class="line"> </span><br><span class="line">result = clf.predict([[<span class="number">2</span>, <span class="number">2</span>]]) <span class="comment"># 预测</span></span><br><span class="line">print(result)  <span class="comment"># 打印</span></span><br></pre></td></tr></table></figure>
<p>调参时直接参考下面三个博客</p>
<p><a href="https://blog.csdn.net/szlcw1/article/details/52336824" target="_blank" rel="noopener">sklearn.svm.SVC 参数说明</a></p>
<p><a href="https://blog.csdn.net/Dream_angel_Z/article/details/47175373" target="_blank" rel="noopener">机器学习-训练模型的保存与恢复（sklearn）</a></p>
<p><a href="[https://xijunlee.github.io/2017/03/29/sklearn%E4%B8%ADSVM%E8%B0%83%E5%8F%82%E8%AF%B4%E6%98%8E%E5%8F%8A%E7%BB%8F%E9%AA%8C%E6%80%BB%E7%BB%93/](https://xijunlee.github.io/2017/03/29/sklearn中SVM调参说明及经验总结/">sklearn中SVM调参说明及经验总结</a>)</p>
<h2><span id="sklearn_svm_trainpy">sklearn_svm_train.py</span></h2><p>直接训练部分代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">Created on Mon May 20 15:07:38 2019</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">@author: Allent_Computer</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> svm</span><br><span class="line"><span class="keyword">from</span> sklearn.externals <span class="keyword">import</span> joblib</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="comment">#from matplotlib import pyplot as plt</span></span><br><span class="line"><span class="keyword">from</span> os.path <span class="keyword">import</span> dirname, join, basename</span><br><span class="line"><span class="keyword">import</span> shutil</span><br><span class="line"><span class="keyword">from</span> glob <span class="keyword">import</span> glob</span><br><span class="line"></span><br><span class="line">bin_n = <span class="number">16</span>*<span class="number">16</span> <span class="comment"># Number of bins</span></span><br><span class="line">(winW, winH) = (<span class="number">64</span>, <span class="number">64</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">hog</span><span class="params">(img)</span>:</span></span><br><span class="line">    x_pixel,y_pixel=<span class="number">352</span>,<span class="number">288</span></span><br><span class="line">    gx = cv2.Sobel(img, cv2.CV_32F, <span class="number">1</span>, <span class="number">0</span>)</span><br><span class="line">    gy = cv2.Sobel(img, cv2.CV_32F, <span class="number">0</span>, <span class="number">1</span>)</span><br><span class="line">    mag, ang = cv2.cartToPolar(gx, gy)</span><br><span class="line">    bins = np.int32(bin_n*ang/(<span class="number">2</span>*np.pi))   </span><br><span class="line">    x_pixel_int=int(x_pixel/<span class="number">2</span>)</span><br><span class="line">    y_pixel_int=int(y_pixel/<span class="number">2</span>)</span><br><span class="line">    bin_cells = bins[:x_pixel_int,:y_pixel_int], bins[x_pixel_int:,:y_pixel_int], bins[:x_pixel_int,y_pixel_int:], bins[x_pixel_int:,y_pixel_int:]</span><br><span class="line">    mag_cells = mag[:x_pixel_int,:y_pixel_int], mag[x_pixel_int:,:y_pixel_int], mag[:x_pixel_int,y_pixel_int:], mag[x_pixel_int:,y_pixel_int:]</span><br><span class="line">    hists = [np.bincount(b.ravel(), m.ravel(), bin_n) <span class="keyword">for</span> b, m <span class="keyword">in</span> zip(bin_cells, mag_cells)]</span><br><span class="line">    hist = np.hstack(hists)     <span class="comment"># hist is a 64 bit vector</span></span><br><span class="line">    <span class="keyword">return</span> hist</span><br><span class="line"></span><br><span class="line">img=&#123;&#125;</span><br><span class="line">num=<span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> fn <span class="keyword">in</span> glob(join(dirname(__file__)+<span class="string">'/posi_resized'</span>, <span class="string">'*.jpg'</span>)):</span><br><span class="line">    img[num] = cv2.imread(fn,<span class="number">0</span>)<span class="comment">#参数加0，只读取黑白数据，去掉0，就是彩色读取。</span></span><br><span class="line">    num=num+<span class="number">1</span></span><br><span class="line">positive=num</span><br><span class="line"><span class="keyword">for</span> fn <span class="keyword">in</span> glob(join(dirname(__file__)+<span class="string">'/nega_resized'</span>, <span class="string">'*.jpg'</span>)):</span><br><span class="line">    img[num] = cv2.imread(fn,<span class="number">0</span>)<span class="comment">#参数加0，只读取黑白数据，去掉0，就是彩色读取。</span></span><br><span class="line">    num=num+<span class="number">1</span></span><br><span class="line"></span><br><span class="line">trainpic=[]</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> img:</span><br><span class="line">    trainpic.append(img[i])</span><br><span class="line"></span><br><span class="line">hogdata=list(map(hog,trainpic))</span><br><span class="line">trainData = np.float32(hogdata).reshape(<span class="number">-1</span>,bin_n*<span class="number">4</span>)</span><br><span class="line">responses = np.int32(np.repeat(<span class="number">1.0</span>,trainData.shape[<span class="number">0</span>]))</span><br><span class="line">responses[positive:trainData.shape[<span class="number">0</span>]]=<span class="number">-1.0</span></span><br><span class="line">trainData=list(trainData)</span><br><span class="line"></span><br><span class="line">test_temp=[]</span><br><span class="line"><span class="keyword">for</span> fn <span class="keyword">in</span> glob(join(dirname(__file__)+<span class="string">'/predict_resized'</span>, <span class="string">'*.jpg'</span>)):</span><br><span class="line">    img=cv2.imread(fn,<span class="number">0</span>)<span class="comment">#参数加0，只读取黑白数据，去掉0，就是彩色读取。</span></span><br><span class="line">    test_temp.append(img)</span><br><span class="line">testdata=list(map(hog,test_temp))</span><br><span class="line">testData = np.float32(testdata).reshape(<span class="number">-1</span>,bin_n*<span class="number">4</span>)</span><br><span class="line"> </span><br><span class="line">model = svm.SVC(C=<span class="number">1</span>,gamma=<span class="number">1</span>,kernel=<span class="string">'linear'</span>,probability=<span class="literal">True</span>)</span><br><span class="line">model.fit(trainData, responses)  <span class="comment"># training the svc model</span></span><br><span class="line">joblib.dump(model, <span class="string">"train_model.m"</span>)</span><br><span class="line"></span><br><span class="line">test_temp=[]</span><br><span class="line"><span class="keyword">for</span> fn <span class="keyword">in</span> glob(join(dirname(__file__)+<span class="string">'/predict_resized'</span>, <span class="string">'*.jpg'</span>)):</span><br><span class="line">    img=cv2.imread(fn,<span class="number">0</span>)<span class="comment">#参数加0，只读取黑白数据，去掉0，就是彩色读取。</span></span><br><span class="line">    test_temp.append(img)</span><br><span class="line">testdata=list(map(hog,test_temp))</span><br><span class="line">testData = np.float32(testdata).reshape(<span class="number">-1</span>,bin_n*<span class="number">4</span>)</span><br><span class="line"><span class="comment">#model.predict(testData)</span></span><br></pre></td></tr></table></figure>
<h2><span id="sklearn_svm_predictpy">sklearn_svm_predict.py</span></h2><p>直接测试图片部分代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">Created on Mon May 20 10:06:37 2019</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">@author: Allent_Computer</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> svm</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> GridSearchCV</span><br><span class="line"><span class="keyword">from</span> sklearn.externals <span class="keyword">import</span> joblib</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="comment">#from matplotlib import pyplot as plt</span></span><br><span class="line"><span class="keyword">from</span> os.path <span class="keyword">import</span> dirname, join, basename</span><br><span class="line"><span class="keyword">import</span> shutil</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">from</span> glob <span class="keyword">import</span> glob</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">bin_n = <span class="number">16</span>*<span class="number">16</span> <span class="comment"># hog中用的</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#通过指定的因子来调整图像的大小</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">frame_resize</span><span class="params">(img, scaleFactor)</span>:</span></span><br><span class="line">  <span class="keyword">return</span> cv2.resize(img, (int(img.shape[<span class="number">1</span>] * (<span class="number">1</span> / scaleFactor)),</span><br><span class="line">    int(img.shape[<span class="number">0</span>] * (<span class="number">1</span> / scaleFactor))), interpolation=cv2.INTER_AREA)</span><br><span class="line"></span><br><span class="line"><span class="comment">#建立图像金字塔，返回被调整过大小的图像直到宽度和高度都达到所规定的最小约束</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">pyramid</span><span class="params">(image, scale=<span class="number">1.5</span>, minSize=<span class="params">(<span class="number">100</span>, <span class="number">80</span>)</span>)</span>:</span></span><br><span class="line">    <span class="comment"># 迭代获取图像</span></span><br><span class="line">    <span class="keyword">yield</span> image</span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">        <span class="comment">#print(image.shape)</span></span><br><span class="line">        image = frame_resize(image, scale)</span><br><span class="line">        <span class="keyword">if</span> image.shape[<span class="number">0</span>] &lt; minSize[<span class="number">1</span>] <span class="keyword">or</span> image.shape[<span class="number">1</span>] &lt; minSize[<span class="number">0</span>]:</span><br><span class="line">            <span class="comment">#print(image.shape)</span></span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">        <span class="keyword">yield</span> image</span><br><span class="line"></span><br><span class="line"><span class="comment">#非极大值抑制，消除重叠窗口</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">py_nms</span><span class="params">(boxs,thresh_l=<span class="number">0</span>, thresh_r=<span class="number">0.9</span>, mode=<span class="string">"Union"</span>)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    greedily select boxes with high confidence</span></span><br><span class="line"><span class="string">    keep boxes overlap &lt;= thresh</span></span><br><span class="line"><span class="string">    rule out overlap &gt; thresh</span></span><br><span class="line"><span class="string">    :param dets: [[x1, y1, x2, y2 score]]</span></span><br><span class="line"><span class="string">    :param thresh: retain overlap &lt;= thresh</span></span><br><span class="line"><span class="string">    :return: indexes to keep</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    dets=np.array(boxs)</span><br><span class="line">    <span class="keyword">if</span> len(dets) == <span class="number">0</span>:</span><br><span class="line">        <span class="keyword">return</span> []</span><br><span class="line">    x1 = dets[:, <span class="number">0</span>]</span><br><span class="line">    y1 = dets[:, <span class="number">1</span>]</span><br><span class="line">    x2 = dets[:, <span class="number">2</span>]</span><br><span class="line">    y2 = dets[:, <span class="number">3</span>]</span><br><span class="line">    scores = dets[:, <span class="number">4</span>]</span><br><span class="line">    areas = (x2 - x1 + <span class="number">1</span>) * (y2 - y1 + <span class="number">1</span>)</span><br><span class="line">    order = scores.argsort()[::<span class="number">-1</span>]</span><br><span class="line">    keep = []</span><br><span class="line">    <span class="keyword">while</span> order.size &gt; <span class="number">0</span>:</span><br><span class="line">        i = order[<span class="number">0</span>]</span><br><span class="line">        keep.append(i)</span><br><span class="line">        xx1 = np.maximum(x1[i], x1[order[<span class="number">1</span>:]])</span><br><span class="line">        yy1 = np.maximum(y1[i], y1[order[<span class="number">1</span>:]])</span><br><span class="line">        xx2 = np.minimum(x2[i], x2[order[<span class="number">1</span>:]])</span><br><span class="line">        yy2 = np.minimum(y2[i], y2[order[<span class="number">1</span>:]])</span><br><span class="line"></span><br><span class="line">        w = np.maximum(<span class="number">0.0</span>, xx2 - xx1 + <span class="number">1</span>)</span><br><span class="line">        h = np.maximum(<span class="number">0.0</span>, yy2 - yy1 + <span class="number">1</span>)</span><br><span class="line">        inter = w * h</span><br><span class="line">        <span class="keyword">if</span> mode == <span class="string">"Union"</span>:</span><br><span class="line">            ovr = inter / (areas[i] + areas[order[<span class="number">1</span>:]] - inter)</span><br><span class="line">        <span class="keyword">elif</span> mode == <span class="string">"Minimum"</span>:</span><br><span class="line">            ovr = inter / np.minimum(areas[i], areas[order[<span class="number">1</span>:]])</span><br><span class="line">        inds = np.where(ovr&lt;=thresh_r)[<span class="number">0</span>]</span><br><span class="line"><span class="comment">#        print((ovr&lt;=thresh_r))</span></span><br><span class="line"><span class="comment">#        print((ovr&gt;=thresh_l))</span></span><br><span class="line"><span class="comment">#        print((ovr&lt;=thresh_r) &amp; (ovr&gt;=thresh_l))</span></span><br><span class="line">        order = order[inds + <span class="number">1</span>]</span><br><span class="line">    <span class="keyword">return</span> dets[keep]</span><br><span class="line"></span><br><span class="line"><span class="comment">#提取图片的hog特征</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">hog</span><span class="params">(img)</span>:</span></span><br><span class="line">    x_pixel,y_pixel=<span class="number">352</span>,<span class="number">288</span></span><br><span class="line">    gx = cv2.Sobel(img, cv2.CV_32F, <span class="number">1</span>, <span class="number">0</span>)</span><br><span class="line">    gy = cv2.Sobel(img, cv2.CV_32F, <span class="number">0</span>, <span class="number">1</span>)</span><br><span class="line">    mag, ang = cv2.cartToPolar(gx, gy)</span><br><span class="line">    bins = np.int32(bin_n*ang/(<span class="number">2</span>*np.pi))   </span><br><span class="line">    x_pixel_int=int(x_pixel/<span class="number">2</span>)</span><br><span class="line">    y_pixel_int=int(y_pixel/<span class="number">2</span>)</span><br><span class="line">    bin_cells = bins[:x_pixel_int,:y_pixel_int], bins[x_pixel_int:,:y_pixel_int], bins[:x_pixel_int,y_pixel_int:], bins[x_pixel_int:,y_pixel_int:]</span><br><span class="line">    mag_cells = mag[:x_pixel_int,:y_pixel_int], mag[x_pixel_int:,:y_pixel_int], mag[:x_pixel_int,y_pixel_int:], mag[x_pixel_int:,y_pixel_int:]</span><br><span class="line">    hists = [np.bincount(b.ravel(), m.ravel(), bin_n) <span class="keyword">for</span> b, m <span class="keyword">in</span> zip(bin_cells, mag_cells)]</span><br><span class="line">    hist = np.hstack(hists)     <span class="comment"># hist is a 64 bit vector</span></span><br><span class="line">    <span class="keyword">return</span> hist</span><br><span class="line"></span><br><span class="line"><span class="comment">#滑动窗口，产生图片用于预测</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sliding_window</span><span class="params">(image, stepSize, windowSize)</span>:</span></span><br><span class="line">    <span class="comment"># slide a window across the image</span></span><br><span class="line">    <span class="keyword">for</span> y <span class="keyword">in</span> range(<span class="number">0</span>, image.shape[<span class="number">0</span>], stepSize):</span><br><span class="line">        <span class="keyword">for</span> x <span class="keyword">in</span> range(<span class="number">0</span>, image.shape[<span class="number">1</span>], stepSize):</span><br><span class="line">            <span class="comment"># yield the current window</span></span><br><span class="line">            <span class="keyword">yield</span> (x, y, image[y:y + windowSize[<span class="number">1</span>], x:x + windowSize[<span class="number">0</span>]])</span><br><span class="line">            </span><br><span class="line"><span class="comment">#获取训练样本，输入到trainData</span></span><br><span class="line">img=&#123;&#125;</span><br><span class="line">num=<span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> fn <span class="keyword">in</span> glob(join(dirname(__file__)+<span class="string">'/posi_resized'</span>, <span class="string">'*.jpg'</span>)):</span><br><span class="line">    img[num] = cv2.imread(fn,<span class="number">0</span>)<span class="comment">#参数加0，只读取黑白数据，去掉0，就是彩色读取。</span></span><br><span class="line">    num=num+<span class="number">1</span></span><br><span class="line">positive=num</span><br><span class="line"><span class="keyword">for</span> fn <span class="keyword">in</span> glob(join(dirname(__file__)+<span class="string">'/nega_resized'</span>, <span class="string">'*.jpg'</span>)):</span><br><span class="line">    img[num] = cv2.imread(fn,<span class="number">0</span>)<span class="comment">#参数加0，只读取黑白数据，去掉0，就是彩色读取。</span></span><br><span class="line">    num=num+<span class="number">1</span></span><br><span class="line">trainpic=[]</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> img:</span><br><span class="line">    trainpic.append(img[i])</span><br><span class="line">hogdata=list(map(hog,trainpic))</span><br><span class="line">trainData = np.float32(hogdata).reshape(<span class="number">-1</span>,bin_n*<span class="number">4</span>)</span><br><span class="line">responses = np.int32(np.repeat(<span class="number">1.0</span>,trainData.shape[<span class="number">0</span>]))</span><br><span class="line">responses[positive:trainData.shape[<span class="number">0</span>]]=<span class="number">-1.0</span></span><br><span class="line">trainData=list(trainData)</span><br><span class="line"></span><br><span class="line"><span class="comment">#获取测试样本，用于测试SVM分类效果</span></span><br><span class="line">test_temp=[]</span><br><span class="line"><span class="keyword">for</span> fn <span class="keyword">in</span> glob(join(dirname(__file__)+<span class="string">'/predict_resized'</span>, <span class="string">'*.jpg'</span>)):</span><br><span class="line">    img=cv2.imread(fn,<span class="number">0</span>)<span class="comment">#参数加0，只读取黑白数据，去掉0，就是彩色读取。</span></span><br><span class="line">    test_temp.append(img)</span><br><span class="line">testdata=list(map(hog,test_temp))</span><br><span class="line">testData = np.float32(testdata).reshape(<span class="number">-1</span>,bin_n*<span class="number">4</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">###该部分为训练过程代码，因为已经保存好m文件，所以注释掉了，直接load训练好的到model</span></span><br><span class="line"><span class="comment">#model = svm.SVC(C=0.01,gamma=1,kernel='linear',probability=True)  # class </span></span><br><span class="line"><span class="comment">#, param_grid=&#123;"C":[0.001, 0.01, 0.1], "gamma": [1, 0.1, 0.01]&#125;, cv=4</span></span><br><span class="line"><span class="comment">#model = GridSearchCV(svm.SVC(probability=True), param_grid=&#123;"C":[0.00001, 0.0001], "gamma": [0.5, 5]&#125;, cv=4)</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#model.fit(trainData, responses)  # training the svc model</span></span><br><span class="line"><span class="comment">#print("The best parameters are %s with a score of %0.2f"</span></span><br><span class="line"><span class="comment">#      % (model.best_params_, model.best_score_))</span></span><br><span class="line"><span class="comment">#joblib.dump(model, "train_model.m")</span></span><br><span class="line"><span class="comment">#result1 = model.predict(testData)</span></span><br><span class="line"><span class="comment">#result2=model.predict_proba(testData)</span></span><br><span class="line"><span class="comment">#print(result1)</span></span><br><span class="line"><span class="comment">#print(result2)</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#load模型到model，并测试</span></span><br><span class="line">model=joblib.load(<span class="string">"E:\\Python\\SVM4Pedestrian\\train_model.m"</span>)</span><br><span class="line">image=cv2.imread(<span class="string">"E:\\Python\\detected_image.jpg"</span>)<span class="comment">#彩色读入，用于显示</span></span><br><span class="line">imggray=cv2.imread(<span class="string">"E:\\Python\\detected_image.jpg"</span>,<span class="number">0</span>)<span class="comment">#灰色读入，用于预测</span></span><br><span class="line">(winW, winH) = (<span class="number">64</span>, <span class="number">64</span>)<span class="comment">#滑动窗口大小</span></span><br><span class="line">winWBox=int(winW)<span class="comment">#存储高斯金字塔缩小的尺寸对应的box应该有多大</span></span><br><span class="line">winHBox=int(winH)</span><br><span class="line">boxs=[]<span class="comment">#存储box，用于非极大抑制</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> img <span class="keyword">in</span> pyramid(imggray,<span class="number">1.5</span>):<span class="comment">#用滑动窗口+非极大抑制数人头</span></span><br><span class="line">    <span class="keyword">for</span> (x, y, window) <span class="keyword">in</span> sliding_window(img, stepSize=<span class="number">21</span>, windowSize=(winW, winH)):</span><br><span class="line">        <span class="keyword">if</span> window.shape[<span class="number">0</span>] != winH <span class="keyword">or</span> window.shape[<span class="number">1</span>] != winW:</span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">        clone = img.copy()</span><br><span class="line">        cv2.rectangle(clone, (x, y), (x + winW, y + winH), (<span class="number">0</span>, <span class="number">255</span>, <span class="number">0</span>), <span class="number">2</span>)</span><br><span class="line">        cut_img=img[y:y + winH,x:x+winW]</span><br><span class="line">        cut_img=cv2.resize(cut_img,(<span class="number">64</span>,<span class="number">128</span>),interpolation=cv2.INTER_AREA)</span><br><span class="line">        data=hog(cut_img)[<span class="literal">None</span>,:]</span><br><span class="line">        data = np.float32(data).reshape(<span class="number">-1</span>,bin_n*<span class="number">4</span>)</span><br><span class="line">        prediction=model.predict_proba(data)[<span class="number">0</span>]</span><br><span class="line">        <span class="keyword">if</span> prediction[<span class="number">1</span>] &gt;<span class="number">0.98</span>:</span><br><span class="line">            scaleBox=float(winWBox)/float(winW)</span><br><span class="line">            box=[x*scaleBox,y*scaleBox,x*scaleBox + winWBox,y*scaleBox + winHBox,prediction[<span class="number">1</span>]]</span><br><span class="line">            boxs.append(box)</span><br><span class="line">        cv2.rectangle(clone, (x, y), (x + winW, y + winH), (<span class="number">0</span>, <span class="number">255</span>, <span class="number">0</span>), <span class="number">2</span>)</span><br><span class="line">        cv2.imshow(<span class="string">"Window"</span>, clone)</span><br><span class="line">        cv2.waitKey(<span class="number">1</span>)</span><br><span class="line">    winWBox=winWBox*<span class="number">1.5</span></span><br><span class="line">    winHBox=winHBox*<span class="number">1.5</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#将结果画图    </span></span><br><span class="line">result=py_nms(boxs,thresh_l=<span class="number">0.0</span>,thresh_r=<span class="number">0.1</span>,mode=<span class="string">"Union"</span>)</span><br><span class="line">saveNum=<span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(len(result)):</span><br><span class="line">    x1=int(result[i][<span class="number">0</span>])</span><br><span class="line">    y1=int(result[i][<span class="number">1</span>])</span><br><span class="line">    x2=int(result[i][<span class="number">2</span>])</span><br><span class="line">    y2=int(result[i][<span class="number">3</span>])</span><br><span class="line">    save_img=image[y1:y2,x1:x2]</span><br><span class="line">    cv2.imwrite(str(saveNum)+<span class="string">".jpg"</span>,save_img)</span><br><span class="line">    saveNum+=<span class="number">1</span></span><br><span class="line">    cv2.rectangle(image, (x1,y1 ), (x2, y2), (<span class="number">0</span>, <span class="number">255</span>, <span class="number">0</span>), <span class="number">1</span>)</span><br><span class="line">    cv2.putText(image,str(saveNum),(x1,y1),cv2.FONT_HERSHEY_SIMPLEX,<span class="number">0.6</span>,(<span class="number">0</span>,<span class="number">255</span>,<span class="number">0</span>),<span class="number">1</span>)</span><br><span class="line">    </span><br><span class="line">cv2.putText(image,<span class="string">"All:"</span>+str(saveNum),(<span class="number">0</span>,<span class="number">15</span>),cv2.FONT_HERSHEY_SIMPLEX,<span class="number">0.6</span>,(<span class="number">0</span>,<span class="number">255</span>,<span class="number">0</span>),<span class="number">1</span>)</span><br><span class="line">    </span><br><span class="line">cv2.imshow(<span class="string">"result:"</span>,image)</span><br><span class="line">k = cv2.waitKey(<span class="number">0</span>) <span class="comment"># waitkey代表读取键盘的输入，括号里的数字代表等待多长时间，单位ms。 0代表一直等待</span></span><br><span class="line"><span class="keyword">if</span> k ==<span class="number">27</span>:     <span class="comment"># 键盘上Esc键的键值</span></span><br><span class="line">    cv2.destroyAllWindows()</span><br><span class="line">cv2.imwrite(<span class="string">"E:\\Python\\SVM4Pedestrian\\result.jpg"</span>,image)</span><br></pre></td></tr></table></figure>
<h2><span id="效果">效果</span></h2><p>多人检测时候的效果如下：</p>
<div align="center"><br><img src="https://github.com/AllentDan/PedestrianDetection/raw/master/images/multiPeople.jpg" alt="多人检测"><br></div>

<p>三人检测时候效果如下：</p>
<div align="center"><br><img src="https://github.com/AllentDan/PedestrianDetection/raw/master/images/threeePeople.jpg" alt="三人检测"><br></div>

<p>单人检测效果如下：</p>
<div align="center"><br><img src="https://github.com/AllentDan/PedestrianDetection/raw/master/images/singlePerson.jpg" alt="cover"><br></div>

<p>可以看到还是有很多问题的，而且这只是找的几个效果还可以的参数下的。想要更加实用，就需要更多的时间调整参数，修改样本，更改步长这种。</p>
<h2><span id="耗时">耗时</span></h2><p>用i7的CPU处理器，时间上是处理一个352*288的图片耗时零点几秒，这样即使是CPU也可以处理一个大概20000帧的视频，用时也就一两个小时</p>
<h1><span id="结论">结论</span></h1><p>好用，快捷，待改进</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/child/2019/05/10/用InceptionV3迁移学习进行客流检测/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Allent Dan">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Allent's Blogs">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/05/10/用InceptionV3迁移学习进行客流检测/" itemprop="url">用InceptionV3迁移学习进行客流检测</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-05-10T19:26:19+08:00">
                2019-05-10
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p><strong>目录 (Table of Contents)</strong><br>[TOC]</p>
<h3><span id="项目背景">项目背景</span></h3><ul>
<li>很久以前自学过<a href="https://www.bilibili.com/video/av20542427" target="_blank" rel="noopener">深度学习框架TensorFlow学习与应用</a>，并且实现里面的大部分代码，其中就包括有Google深度学习模型<a href="https://github.com/tensorflow/models/tree/master/research/inception" target="_blank" rel="noopener">Inception v3</a>,Incetption模型是谷歌基于开源项目Tensorflow的一款深度学习模型，能够识别千种以上的对象，并且进行过优化，适合迁移学习使用</li>
<li>刚刚给公司新买的GPU配置好<a href="https://allentdan.github.io/2019/05/10/Anaconda-Tensorflow-gpu%E9%85%8D%E7%BD%AE/" target="_blank" rel="noopener">Anaconda+Tensorflow_gpu环境</a></li>
<li>学校《图像处理》课程结束大作业就是公交车上的行人检测，要求统计实时乘客流量并且款选出每个人，越准确越好</li>
</ul>
<div align="center"><br><img src="/images/good_para.jpg" alt="result.jpg"><br></div>



<h2><span id="下载inception-v3">下载Inception v3</span></h2><p>Inception v3模型已经在项目背景给出，下载后存盘，我的路径是</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">E:\Python\测试下载\tensorflow\inception_model</span><br></pre></td></tr></table></figure>
<p>你只要存到你想要放置的位置就好，因为后面调用的时候会设置路径。文件夹里面是<br><img src="/images/Inception v3.jpg" alt="Inception v3"><br>迁移学习训练时候主要调用的就是这个tgz压缩包。</p>
<h2><span id="使用数据集vgg">使用数据集VGG</span></h2><p>进入<a href="http://www.robots.ox.ac.uk/~vgg/data/" target="_blank" rel="noopener">VGG数据集</a>，下载几个分类的图片，我个人下载了flower, airplane, guitars, animal and motorbikes，每个分类保存大概500张左右用于训练。里面图片类似这种</p>
<div align="center"><br><img src="/images/flower_0003.jpg" alt="flower"><br></div><br><div align="center"><br><img src="/images/guitar0001.jpg" alt="guitar"><br></div>

<p>好了，现在我们有五个分类的文件夹，每个里面大概存有500张图片。</p>
<p>现在我们进行训练，参考项目背景中的视频，编写批处理文件retrain.bat，文件内容如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">python E:/Python/测试下载/tensorflow/retrain.py ^</span><br><span class="line">--bottleneck_dir bottleneck ^</span><br><span class="line">--how_many_training_steps 40 ^</span><br><span class="line">--model_dir E:/Python/测试下载/tensorflow/inception_model/ ^</span><br><span class="line">--output_graph output_graph.pb ^</span><br><span class="line">--output_labels output_labels.txt ^</span><br><span class="line">--image_dir data/train/</span><br><span class="line">pause</span><br></pre></td></tr></table></figure>
<p>第一行表示一个Python文件的存放位置，通过调用重新训练模型，文件内容太长就不贴了，地址在<a href="https://github.com/tensorflow/hub/blob/master/examples/image_retraining/retrain.py" target="_blank" rel="noopener">这</a>；<br>第二行表示Inception v3的输出瓶颈位置，需要我们在批处理文件的目录下新建bottleneck文件夹，用于存放训练产生数据；<br>第三行表示训练次数，由你喜欢，可以来个一两百次，比较GPU无压力，我之前用cpu跑贼慢，跑完系统还崩了，然后模型测试结果也不对，不过神奇的是过了一天什么也没干过，结果用预测对了，简直玄学；<br>第四行表示之前下载的Inception v3的位置，给我们调用；<br>第五，六行表示将结果保存到批处理文件的目录下，是两个文件.pb和.txt，分别存放模型和标签；<br>第七行表示我们下载好的VGG图片，分为五类在五个文件夹内，文件夹名字均小写，且图片格式均为.bmp，否则会训练失败，这五个文件夹就保存在data/train/文件夹里面，data和train文件夹均是我们新建的，data文件夹存放在批处理文件目录下。<br>然后我们开始跑程序吧，点击retrain.bat然后等待几分钟，结果就是，嘣……</p>
<h2><span id="训练结果测试">训练结果测试</span></h2><p>不用贴图，训练成功你一定是看得出来的。直接从之前五类图片里面挑几个非训练图片出来用于测试，代码贴上来：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"> </span><br><span class="line">lines = tf.gfile.GFile(<span class="string">'retrain/output_labels.txt'</span>).readlines()</span><br><span class="line">uid_to_human = &#123;&#125;</span><br><span class="line"><span class="comment">#一行一行读取数据</span></span><br><span class="line"><span class="keyword">for</span> uid,line <span class="keyword">in</span> enumerate(lines) :</span><br><span class="line">    <span class="comment">#去掉换行符</span></span><br><span class="line">    line=line.strip(<span class="string">'\n'</span>)</span><br><span class="line">    uid_to_human[uid] = line</span><br><span class="line"> </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">id_to_string</span><span class="params">(node_id)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> node_id <span class="keyword">not</span> <span class="keyword">in</span> uid_to_human:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">''</span></span><br><span class="line">    <span class="keyword">return</span> uid_to_human[node_id]</span><br><span class="line"> </span><br><span class="line"><span class="keyword">with</span> tf.gfile.FastGFile(<span class="string">'retrain/output_graph.pb'</span>, <span class="string">'rb'</span>) <span class="keyword">as</span> f:</span><br><span class="line">    graph_def = tf.GraphDef()</span><br><span class="line">    graph_def.ParseFromString(f.read())</span><br><span class="line">    tf.import_graph_def(graph_def, name=<span class="string">''</span>)</span><br><span class="line">    </span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    softmax_tensor = sess.graph.get_tensor_by_name(<span class="string">'final_result:0'</span>)</span><br><span class="line">    <span class="comment">#遍历目录</span></span><br><span class="line">    <span class="keyword">for</span> root,dirs,files <span class="keyword">in</span> os.walk(<span class="string">'retrain/images/'</span>):</span><br><span class="line">        <span class="keyword">for</span> file <span class="keyword">in</span> files:</span><br><span class="line">            <span class="comment">#载入图片</span></span><br><span class="line">            image_data = tf.gfile.FastGFile(os.path.join(root,file), <span class="string">'rb'</span>).read()</span><br><span class="line">            predictions = sess.run(softmax_tensor,&#123;<span class="string">'DecodeJpeg/contents:0'</span>: image_data&#125;)<span class="comment">#图片格式是jpg格式</span></span><br><span class="line">            predictions = np.squeeze(predictions)<span class="comment">#把结果转为1维数据</span></span><br><span class="line"> </span><br><span class="line">            <span class="comment">#打印图片路径及名称</span></span><br><span class="line">            image_path = os.path.join(root,file)</span><br><span class="line">            print(image_path)</span><br><span class="line">            <span class="comment">#显示图片</span></span><br><span class="line">            img=Image.open(image_path)</span><br><span class="line">            plt.imshow(img)</span><br><span class="line">            plt.axis(<span class="string">'off'</span>)</span><br><span class="line">            plt.show()</span><br><span class="line"> </span><br><span class="line">            <span class="comment">#排序</span></span><br><span class="line">            top_k = predictions.argsort()[::<span class="number">-1</span>]</span><br><span class="line">            print(top_k)</span><br><span class="line">            <span class="keyword">for</span> node_id <span class="keyword">in</span> top_k:     </span><br><span class="line">                <span class="comment">#获取分类名称</span></span><br><span class="line">                human_string = id_to_string(node_id)</span><br><span class="line">                <span class="comment">#获取该分类的置信度</span></span><br><span class="line">                score = predictions[node_id]</span><br><span class="line">                print(<span class="string">'%s (score = %.5f)'</span> % (human_string, score))</span><br><span class="line">            print()</span><br></pre></td></tr></table></figure>
<p>注意改下里面的模型.pb .txt和测试图片image的路径到你本地位置。然后就是见证奇迹的时刻：</p>
<div align="center"><br><img src="/images/试用Inception.jpg" alt="试用Inception结果"><br></div>

<h1><span id="从待检测视频中剪出样本用于训练">从待检测视频中剪出样本用于训练</span></h1><h2><span id="直接上代码">直接上代码</span></h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">global</span> frame</span><br><span class="line"><span class="keyword">global</span> c, folder</span><br><span class="line"><span class="keyword">global</span> point1, point2</span><br><span class="line"><span class="keyword">import</span> tkinter <span class="keyword">as</span> tk</span><br><span class="line"><span class="keyword">from</span> tkinter <span class="keyword">import</span> filedialog</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">on_mouse</span><span class="params">(event, x, y, flags, param)</span>:</span></span><br><span class="line">    <span class="keyword">global</span> c</span><br><span class="line">    <span class="keyword">global</span> folder</span><br><span class="line">    <span class="keyword">global</span> frame, point1, point2</span><br><span class="line">    img2 = frame.copy()</span><br><span class="line">    <span class="keyword">if</span> event == cv2.EVENT_LBUTTONDOWN:         <span class="comment">#左键点击</span></span><br><span class="line">        point1 = (x,y)</span><br><span class="line">        cv2.circle(img2, point1, <span class="number">10</span>, (<span class="number">0</span>,<span class="number">255</span>,<span class="number">0</span>), <span class="number">5</span>)</span><br><span class="line">        cv2.imshow(<span class="string">'image'</span>, img2)</span><br><span class="line">    <span class="keyword">elif</span> event == cv2.EVENT_MOUSEMOVE <span class="keyword">and</span> (flags &amp; cv2.EVENT_FLAG_LBUTTON):   <span class="comment">#按住左键拖曳</span></span><br><span class="line">        cv2.rectangle(img2, point1, (x,y), (<span class="number">255</span>,<span class="number">0</span>,<span class="number">0</span>), <span class="number">5</span>) <span class="comment"># 图像，矩形顶点，相对顶点，颜色，粗细</span></span><br><span class="line">        cv2.imshow(<span class="string">'image'</span>, img2)</span><br><span class="line">    <span class="keyword">elif</span> event == cv2.EVENT_LBUTTONUP:         <span class="comment">#左键释放</span></span><br><span class="line">        point2 = (x,y)</span><br><span class="line">        cv2.rectangle(img2, point1, point2, (<span class="number">0</span>,<span class="number">0</span>,<span class="number">255</span>), <span class="number">5</span>) </span><br><span class="line">        cv2.imshow(<span class="string">'image'</span>, img2)</span><br><span class="line">        min_x = min(point1[<span class="number">0</span>], point2[<span class="number">0</span>])     </span><br><span class="line">        min_y = min(point1[<span class="number">1</span>], point2[<span class="number">1</span>])</span><br><span class="line">        width = abs(point1[<span class="number">0</span>] - point2[<span class="number">0</span>])</span><br><span class="line">        height = abs(point1[<span class="number">1</span>] -point2[<span class="number">1</span>])</span><br><span class="line">        cut_img = frame[min_y:min_y+height, min_x:min_x+width]</span><br><span class="line">        cv2.imwrite(folder+str(c)+<span class="string">'.jpg'</span>,cut_img)  <span class="comment"># 预处理后图像保存位置</span></span><br><span class="line">        print(c)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">(file_path)</span>:</span></span><br><span class="line">    <span class="keyword">global</span> c</span><br><span class="line">    c=<span class="number">0</span></span><br><span class="line">    <span class="keyword">global</span> frame</span><br><span class="line">    <span class="keyword">global</span> folder</span><br><span class="line">    folder = os.getcwd() + <span class="string">'\\toSave\\'</span></span><br><span class="line">    print(folder)</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(folder):</span><br><span class="line">        os.makedirs(folder)</span><br><span class="line">    </span><br><span class="line">    vc=cv2.VideoCapture(file_path)</span><br><span class="line">    <span class="keyword">if</span> vc.isOpened():</span><br><span class="line">        rval,frame=vc.read()</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        rval=<span class="literal">False</span></span><br><span class="line">    <span class="keyword">while</span> rval:</span><br><span class="line">        <span class="keyword">if</span> c%<span class="number">2</span>==<span class="number">0</span>: <span class="comment">#设置放慢播放速度，方便我截图</span></span><br><span class="line">            rval,frame=vc.read()</span><br><span class="line">            cv2.namedWindow(<span class="string">'image'</span>)</span><br><span class="line">            cv2.setMouseCallback(<span class="string">'image'</span>, on_mouse) <span class="comment"># 调用回调函数</span></span><br><span class="line">            cv2.imshow(<span class="string">'image'</span>, frame)</span><br><span class="line"><span class="comment">#            cv2.imwrite('e:/Git/test/'+str(c)+'.jpg',frame)</span></span><br><span class="line">        c=c+<span class="number">1</span></span><br><span class="line">        cv2.waitKey(<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">if</span> cv2.waitKey(<span class="number">25</span>) &amp; <span class="number">0xFF</span> == ord(<span class="string">'q'</span>):</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">    vc.release()</span><br><span class="line">    cv2.destroyAllWindows()</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    print(<span class="string">"请打开视频文件"</span>)  <span class="comment">#点击视频，会自动播放，用鼠标款选就好，存图到tosave文件夹</span></span><br><span class="line">    root = tk.Tk()</span><br><span class="line">    root.withdraw()</span><br><span class="line">    file_path = filedialog.askopenfilename()</span><br><span class="line">    print(file_path)</span><br><span class="line">    main(file_path)</span><br></pre></td></tr></table></figure>
<p>如果纯手工裁剪图片不知道要猴年马月，用脚本后，正样本（含有检测目标人的）剪出500张花了大概两小时不到，因为开始代码没完善好….<br>负样本的话，如果人少，简直不要太快，十几分钟裁好五百多张。</p>
<h1><span id="训练分类">训练分类</span></h1><p>只放入正样本</p>
<p>一开始，没有制作负样本，就纯拿正样本放入之前的五个分类所在的文件夹，新建分类mypassengers，里面放入我的正样本图片，然后重新点击批处理文件训练，结束后进行测试，当然结果会很好。对含有样本图片和其他图片如吉他这种的区分明显，样本图片预测置信度在0.95以上。可能你会觉得可以直接用滑动窗口往网络里面塞图片进行测试了，但是当我把视频里面不含有人的部分也放到里面的时候，会发现是这样的：</p>
<p>额…忘记截图了，反正就是如果不把视频中不含有人的部分也放进去训练，模型也会认为它是目标，然后就没有做区分，这是相当于训练的时候并没有告诉模型需要对公交车内的人和其他物件如窗户椅子做出区分，所以需要制作负样本同样放进去一起训练。</p>
<h2><span id="多建一个分类放负样本">多建一个分类放负样本</span></h2><p>嘣~结果非常好，暂时就先不贴图了，后面再更，包括引入滑动窗口对整张图片做识别。</p>
<p>………………………..</p>
<p>好了，2019年5月13日下午，我又回来了。像我之前所说，同时截出正负样本进行训练，然后用滑动窗口复制出许许多多的测试图放入网络中测试。</p>
<h1><span id="滑动窗口对视频截图检测客流">滑动窗口对视频截图检测客流</span></h1><h2><span id="滑动窗口">滑动窗口</span></h2><div align="center"><br><img src="https://pic1.xuehuaimg.com/proxy/csdn/https://img-blog.csdnimg.cn/201812242005033.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L20wXzM3OTcwMjI0,size_16,color_FFFFFF,t_70" alt="img"><br></div><br><div align="center"><br>&gt; 图为：滑窗法的物体检测流程图<br></div>

<p>可以发现滑窗的原理和实现都不难，比较关键的一步是需要非极大抑制，直接贴网上找来用的代码如下，helper.py给后面的主程序调用</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">Created on Fri May 10 13:43:36 2019</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">@author: Allent_Computer</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># import the necessary packages</span></span><br><span class="line"><span class="keyword">import</span> imutils</span><br><span class="line"><span class="keyword">from</span> skimage.transform <span class="keyword">import</span> pyramid_gaussian</span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">pyramid</span><span class="params">(image, scale=<span class="number">1.5</span>, minSize=<span class="params">(<span class="number">70</span>, <span class="number">70</span>)</span>)</span>:</span></span><br><span class="line">    <span class="comment"># yield the original image</span></span><br><span class="line">    <span class="keyword">yield</span> image</span><br><span class="line">    loop=<span class="number">1</span></span><br><span class="line">    <span class="comment"># keep looping over the pyramid</span></span><br><span class="line">    <span class="keyword">while</span> loop:</span><br><span class="line">        loop-=<span class="number">1</span></span><br><span class="line">        <span class="comment"># compute the new dimensions of the image and resize it</span></span><br><span class="line">        w = int(image.shape[<span class="number">1</span>] / scale)</span><br><span class="line">        image = imutils.resize(image, width=w)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># if the resized image does not meet the supplied minimum</span></span><br><span class="line">        <span class="comment"># size, then stop constructing the pyramid</span></span><br><span class="line">        <span class="keyword">if</span> image.shape[<span class="number">0</span>] &lt; minSize[<span class="number">1</span>] <span class="keyword">or</span> image.shape[<span class="number">1</span>] &lt; minSize[<span class="number">0</span>]:</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># yield the next image in the pyramid</span></span><br><span class="line">        <span class="keyword">yield</span> image</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sliding_window</span><span class="params">(image, stepSize, windowSize)</span>:</span></span><br><span class="line">    <span class="comment"># slide a window across the image</span></span><br><span class="line">    <span class="keyword">for</span> y <span class="keyword">in</span> range(<span class="number">0</span>, image.shape[<span class="number">0</span>], stepSize):</span><br><span class="line">        <span class="keyword">for</span> x <span class="keyword">in</span> range(<span class="number">0</span>, image.shape[<span class="number">1</span>], stepSize):</span><br><span class="line">            <span class="comment"># yield the current window</span></span><br><span class="line">            <span class="keyword">yield</span> (x, y, image[y:y + windowSize[<span class="number">1</span>], x:x + windowSize[<span class="number">0</span>]])</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    image = cv2.imread(<span class="string">'E:/python/myInceptionProject/detected_image.jpg'</span>)  </span><br><span class="line">    <span class="comment"># METHOD #2: Resizing + Gaussian smoothing.</span></span><br><span class="line">    <span class="keyword">for</span> (i, resized) <span class="keyword">in</span> enumerate(pyramid_gaussian(image, downscale=<span class="number">3</span>)):</span><br><span class="line">        <span class="comment"># if the image is too small, break from the loop</span></span><br><span class="line">        <span class="keyword">if</span> resized.shape[<span class="number">0</span>] &lt; <span class="number">30</span> <span class="keyword">or</span> resized.shape[<span class="number">1</span>] &lt; <span class="number">30</span>:</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">        <span class="comment"># show the resized image</span></span><br><span class="line">        WinName = <span class="string">"Layer &#123;&#125;"</span>.format(i + <span class="number">1</span>)</span><br><span class="line"><span class="comment">#        cv2.imshow(WinName, resized)</span></span><br><span class="line"><span class="comment">#        cv2.waitKey(10)</span></span><br><span class="line">        resized = resized*<span class="number">255</span></span><br><span class="line">        cv2.imwrite(<span class="string">'./'</span>+WinName+<span class="string">'.jpg'</span>,resized)</span><br></pre></td></tr></table></figure>
<p>然后是滑动窗口slideMask.py</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">Created on Fri May 10 10:55:08 2019</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">@author: Allent_Computer</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="comment"># import the necessary packages</span></span><br><span class="line"><span class="keyword">import</span> helpers</span><br><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># load the image and define the window width and height</span></span><br><span class="line">image = cv2.imread(<span class="string">'E:/python/myInceptionProject/detected_image.jpg'</span>)  </span><br><span class="line">(winW, winH) = (<span class="number">60</span>, <span class="number">48</span>)</span><br><span class="line"></span><br><span class="line">i=<span class="number">1</span></span><br><span class="line"><span class="comment"># loop over the image pyramid</span></span><br><span class="line"><span class="keyword">for</span> resized <span class="keyword">in</span> helpers.pyramid(image, scale=<span class="number">1.5</span>):</span><br><span class="line">    <span class="comment"># loop over the sliding window for each layer of the pyramid</span></span><br><span class="line">    <span class="keyword">for</span> (x, y, window) <span class="keyword">in</span> helpers.sliding_window(resized, stepSize=<span class="number">16</span>, windowSize=(winW, winH)):</span><br><span class="line">        <span class="comment"># if the window does not meet our desired window size, ignore it</span></span><br><span class="line">        <span class="keyword">if</span> window.shape[<span class="number">0</span>] != winH <span class="keyword">or</span> window.shape[<span class="number">1</span>] != winW:</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># THIS IS WHERE YOU WOULD PROCESS YOUR WINDOW, SUCH AS APPLYING A</span></span><br><span class="line">        <span class="comment"># MACHINE LEARNING CLASSIFIER TO CLASSIFY THE CONTENTS OF THE</span></span><br><span class="line">        <span class="comment"># WINDOW</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># since we do not have a classifier, we'll just draw the window</span></span><br><span class="line">        clone = resized.copy()</span><br><span class="line"><span class="comment">#        cv2.rectangle(clone, (x, y), (x + winW, y + winH), (0, 255, 0), 2)</span></span><br><span class="line">        cut_img=clone[y:y + winH,x:x+winH]</span><br><span class="line">        cv2.imwrite(<span class="string">"E:/python/myInceptionProject/cut_img/"</span>+str(i)+<span class="string">'.jpg'</span>,cut_img)</span><br><span class="line">        i+=<span class="number">1</span></span><br><span class="line"><span class="comment">#        print(img)</span></span><br><span class="line"><span class="comment">#        cv2.rectangle(clone, (x, y), (x + winW, y + winH), (0, 255, 0), 2)</span></span><br><span class="line"><span class="comment">#        cv2.imshow("Window", clone)</span></span><br><span class="line"><span class="comment">#        cv2.waitKey(1)</span></span><br><span class="line"><span class="comment">#    k = cv2.waitKey(0) # waitkey代表读取键盘的输入，括号里的数字代表等待多长时间，单位ms。 0代表一直等待</span></span><br><span class="line"><span class="comment">#    if k ==27:     # 键盘上Esc键的键值</span></span><br><span class="line"><span class="comment">#        cv2.destroyAllWindows()</span></span><br><span class="line"><span class="comment">#    continue</span></span><br><span class="line"><span class="comment">#         time.sleep(0.025)</span></span><br></pre></td></tr></table></figure>
<p>源码是在网上找的然后手动修改。</p>
<h2><span id="非极大值抑制并检测乘客">非极大值抑制并检测乘客</span></h2><p>如果不加入极大值抑制，后面检测后的结果就很难看。极大值抑制函数如下，boxs是存放窗口box的list，box也是list，里面是窗口的左上角位置x和y以及该窗口的得分（预测置信度）。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">py_nms</span><span class="params">(boxs, thresh=<span class="number">0.9</span>, mode=<span class="string">"Union"</span>)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    greedily select boxes with high confidence</span></span><br><span class="line"><span class="string">    keep boxes overlap &lt;= thresh</span></span><br><span class="line"><span class="string">    rule out overlap &gt; thresh</span></span><br><span class="line"><span class="string">    :param dets: [[x1, y1, x2, y2 score]]</span></span><br><span class="line"><span class="string">    :param thresh: retain overlap &lt;= thresh</span></span><br><span class="line"><span class="string">    :return: indexes to keep</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    dets=np.array(boxs)</span><br><span class="line">    <span class="keyword">if</span> len(dets) == <span class="number">0</span>:</span><br><span class="line">        <span class="keyword">return</span> []</span><br><span class="line">    x1 = dets[:, <span class="number">0</span>]</span><br><span class="line">    y1 = dets[:, <span class="number">1</span>]</span><br><span class="line">    scores = dets[:, <span class="number">2</span>]</span><br><span class="line">    x2 = x1+winW</span><br><span class="line">    y2 = y1+winW</span><br><span class="line">    </span><br><span class="line"></span><br><span class="line">    areas = (x2 - x1 + <span class="number">1</span>) * (y2 - y1 + <span class="number">1</span>)</span><br><span class="line">    order = scores.argsort()[::<span class="number">-1</span>]</span><br><span class="line"></span><br><span class="line">    keep = []</span><br><span class="line">    <span class="keyword">while</span> order.size &gt; <span class="number">0</span>:</span><br><span class="line">        i = order[<span class="number">0</span>]</span><br><span class="line">        keep.append(i)</span><br><span class="line">        xx1 = np.maximum(x1[i], x1[order[<span class="number">1</span>:]])</span><br><span class="line">        yy1 = np.maximum(y1[i], y1[order[<span class="number">1</span>:]])</span><br><span class="line">        xx2 = np.minimum(x2[i], x2[order[<span class="number">1</span>:]])</span><br><span class="line">        yy2 = np.minimum(y2[i], y2[order[<span class="number">1</span>:]])</span><br><span class="line"></span><br><span class="line">        w = np.maximum(<span class="number">0.0</span>, xx2 - xx1 + <span class="number">1</span>)</span><br><span class="line">        h = np.maximum(<span class="number">0.0</span>, yy2 - yy1 + <span class="number">1</span>)</span><br><span class="line">        inter = w * h</span><br><span class="line">        <span class="keyword">if</span> mode == <span class="string">"Union"</span>:</span><br><span class="line">            ovr = inter / (areas[i] + areas[order[<span class="number">1</span>:]] - inter)</span><br><span class="line">        <span class="keyword">elif</span> mode == <span class="string">"Minimum"</span>:</span><br><span class="line">            ovr = inter / np.minimum(areas[i], areas[order[<span class="number">1</span>:]])</span><br><span class="line"></span><br><span class="line">        inds = np.where(ovr &lt;= thresh)[<span class="number">0</span>]</span><br><span class="line">        order = order[inds + <span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> dets[keep]</span><br></pre></td></tr></table></figure>
<p>此时，我对之前po出的训练结果测试的代码做了些修改，然后直接读图，整体测试代码如下</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># coding: utf-8</span></span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> helpers</span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> imutils</span><br><span class="line"> </span><br><span class="line"><span class="comment"># load the image and define the window width and height</span></span><br><span class="line">image = cv2.imread(<span class="string">'E:/python/myInceptionProject/test_img/ped_sample1900.jpg'</span>)  </span><br><span class="line">(winW, winH) = (<span class="number">60</span>, <span class="number">48</span>)</span><br><span class="line"></span><br><span class="line">lines = tf.gfile.GFile(<span class="string">'retrain/output_labels.txt'</span>).readlines()</span><br><span class="line">uid_to_human = &#123;&#125;</span><br><span class="line">k=<span class="number">2</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">py_nms</span><span class="params">(boxs, thresh=<span class="number">0.9</span>, mode=<span class="string">"Union"</span>)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    greedily select boxes with high confidence</span></span><br><span class="line"><span class="string">    keep boxes overlap &lt;= thresh</span></span><br><span class="line"><span class="string">    rule out overlap &gt; thresh</span></span><br><span class="line"><span class="string">    :param dets: [[x1, y1, x2, y2 score]]</span></span><br><span class="line"><span class="string">    :param thresh: retain overlap &lt;= thresh</span></span><br><span class="line"><span class="string">    :return: indexes to keep</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    dets=np.array(boxs)</span><br><span class="line">    <span class="keyword">if</span> len(dets) == <span class="number">0</span>:</span><br><span class="line">        <span class="keyword">return</span> []</span><br><span class="line">    x1 = dets[:, <span class="number">0</span>]</span><br><span class="line">    y1 = dets[:, <span class="number">1</span>]</span><br><span class="line">    scores = dets[:, <span class="number">2</span>]</span><br><span class="line">    x2 = x1+winW</span><br><span class="line">    y2 = y1+winW</span><br><span class="line">    </span><br><span class="line"></span><br><span class="line">    areas = (x2 - x1 + <span class="number">1</span>) * (y2 - y1 + <span class="number">1</span>)</span><br><span class="line">    order = scores.argsort()[::<span class="number">-1</span>]</span><br><span class="line"></span><br><span class="line">    keep = []</span><br><span class="line">    <span class="keyword">while</span> order.size &gt; <span class="number">0</span>:</span><br><span class="line">        i = order[<span class="number">0</span>]</span><br><span class="line">        keep.append(i)</span><br><span class="line">        xx1 = np.maximum(x1[i], x1[order[<span class="number">1</span>:]])</span><br><span class="line">        yy1 = np.maximum(y1[i], y1[order[<span class="number">1</span>:]])</span><br><span class="line">        xx2 = np.minimum(x2[i], x2[order[<span class="number">1</span>:]])</span><br><span class="line">        yy2 = np.minimum(y2[i], y2[order[<span class="number">1</span>:]])</span><br><span class="line"></span><br><span class="line">        w = np.maximum(<span class="number">0.0</span>, xx2 - xx1 + <span class="number">1</span>)</span><br><span class="line">        h = np.maximum(<span class="number">0.0</span>, yy2 - yy1 + <span class="number">1</span>)</span><br><span class="line">        inter = w * h</span><br><span class="line">        <span class="keyword">if</span> mode == <span class="string">"Union"</span>:</span><br><span class="line">            ovr = inter / (areas[i] + areas[order[<span class="number">1</span>:]] - inter)</span><br><span class="line">        <span class="keyword">elif</span> mode == <span class="string">"Minimum"</span>:</span><br><span class="line">            ovr = inter / np.minimum(areas[i], areas[order[<span class="number">1</span>:]])</span><br><span class="line"></span><br><span class="line">        inds = np.where(ovr &lt;= thresh)[<span class="number">0</span>]</span><br><span class="line">        order = order[inds + <span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> dets[keep]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#一行一行读取数据</span></span><br><span class="line"><span class="keyword">for</span> uid,line <span class="keyword">in</span> enumerate(lines) :</span><br><span class="line">    <span class="comment">#去掉换行符</span></span><br><span class="line">    line=line.strip(<span class="string">'\n'</span>)</span><br><span class="line">    uid_to_human[uid] = line</span><br><span class="line"> </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">id_to_string</span><span class="params">(node_id)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> node_id <span class="keyword">not</span> <span class="keyword">in</span> uid_to_human:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">''</span></span><br><span class="line">    <span class="keyword">return</span> uid_to_human[node_id]</span><br><span class="line"> </span><br><span class="line"><span class="keyword">with</span> tf.gfile.FastGFile(<span class="string">'retrain/output_graph.pb'</span>, <span class="string">'rb'</span>) <span class="keyword">as</span> f:</span><br><span class="line">    graph_def = tf.GraphDef()</span><br><span class="line">    graph_def.ParseFromString(f.read())</span><br><span class="line">    tf.import_graph_def(graph_def, name=<span class="string">''</span>)</span><br><span class="line">    </span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    softmax_tensor = sess.graph.get_tensor_by_name(<span class="string">'final_result:0'</span>)</span><br><span class="line">    <span class="comment">#遍历目录</span></span><br><span class="line">scale=<span class="number">2.5</span></span><br><span class="line">w = int(image.shape[<span class="number">1</span>] / scale)</span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    softmax_tensor = sess.graph.get_tensor_by_name(<span class="string">'final_result:0'</span>)</span><br><span class="line">    <span class="comment">#遍历目录</span></span><br><span class="line">    <span class="keyword">for</span> root,dirs,files <span class="keyword">in</span> os.walk(<span class="string">'E:/python/myInceptionProject/test_img/'</span>):</span><br><span class="line">        <span class="keyword">for</span> file <span class="keyword">in</span> files:</span><br><span class="line">            boxs=[]</span><br><span class="line">            image=cv2.imread(os.path.join(root,file))</span><br><span class="line">            resized = imutils.resize(image, width=w)</span><br><span class="line">            <span class="comment">#for resized in helpers.pyramid(image, scale=1.5):</span></span><br><span class="line">                <span class="comment"># loop over the sliding window for each layer of the pyramid</span></span><br><span class="line">            <span class="keyword">for</span> (x, y, window) <span class="keyword">in</span> helpers.sliding_window(resized, stepSize=<span class="number">16</span>, windowSize=(winW, winH)):</span><br><span class="line">                <span class="comment"># if the window does not meet our desired window size, ignore it</span></span><br><span class="line">                <span class="keyword">if</span> window.shape[<span class="number">0</span>] != winH <span class="keyword">or</span> window.shape[<span class="number">1</span>] != winW:</span><br><span class="line">                    <span class="keyword">continue</span></span><br><span class="line">                clone = resized.copy()</span><br><span class="line">            <span class="comment">#        cv2.rectangle(clone, (x, y), (x + winW, y + winH), (0, 255, 0), 2)</span></span><br><span class="line">                cut_img=clone[y:y + winH,x:x+winH]</span><br><span class="line">                cv2.imwrite(<span class="string">"E:/python/myInceptionProject/cut_img/1.jpg"</span>,cut_img)</span><br><span class="line">                <span class="comment">#载入图片</span></span><br><span class="line">                image_data = tf.gfile.FastGFile(<span class="string">"E:/python/myInceptionProject/cut_img/1.jpg"</span>, <span class="string">'rb'</span>).read()</span><br><span class="line">                predictions = sess.run(softmax_tensor,&#123;<span class="string">'DecodeJpeg/contents:0'</span>: image_data&#125;)<span class="comment">#图片格式是jpg格式</span></span><br><span class="line">                predictions = np.squeeze(predictions)<span class="comment">#把结果转为1维数据</span></span><br><span class="line">                </span><br><span class="line">                <span class="comment">#排序</span></span><br><span class="line">                top_k = predictions.argsort()[::<span class="number">-1</span>]</span><br><span class="line">                <span class="keyword">if</span> top_k[<span class="number">0</span>]==<span class="number">3</span> <span class="keyword">and</span> predictions[top_k[<span class="number">0</span>]]&gt;<span class="number">0.92</span>:</span><br><span class="line">                    box=[x,y,predictions[top_k[<span class="number">0</span>]]]</span><br><span class="line">                    boxs.append(box)</span><br><span class="line"><span class="comment">#                    cv2.rectangle(image, (int_x, int_y), (int_x + int_winW, int_y + int_winW), (0, 255, 0), 1)</span></span><br><span class="line">                    <span class="comment">#打印图片路径及名称</span></span><br><span class="line">            <span class="comment">#            image_path = os.path.join(root,file)</span></span><br><span class="line">            <span class="comment">#            print(image_path)</span></span><br><span class="line">                    <span class="comment">#显示图片</span></span><br><span class="line">            <span class="comment">#            img=Image.open(image_path)</span></span><br><span class="line"><span class="comment">#                    plt.imshow(cut_img)</span></span><br><span class="line"><span class="comment">#                    plt.axis('off')</span></span><br><span class="line"><span class="comment">#                    plt.show()</span></span><br><span class="line"><span class="comment">#                    print(top_k)</span></span><br><span class="line">                    <span class="keyword">for</span> node_id <span class="keyword">in</span> top_k:     </span><br><span class="line">                        <span class="comment">#获取分类名称</span></span><br><span class="line">                        human_string = id_to_string(node_id)</span><br><span class="line">                        <span class="comment">#获取该分类的置信度</span></span><br><span class="line">                        score = predictions[node_id]</span><br><span class="line">                        print(<span class="string">'%s (score = %.5f)'</span> % (human_string, score))</span><br><span class="line">            result=py_nms(boxs,thresh=<span class="number">0.3</span>,mode=<span class="string">"Union"</span>)</span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> range(len(result)):</span><br><span class="line">                int_x=int(result[i][<span class="number">0</span>]*scale)</span><br><span class="line">                int_y=int(result[i][<span class="number">1</span>]*scale)</span><br><span class="line">                int_winW=int(winW*scale)</span><br><span class="line">                int_winH=int(winH*scale)</span><br><span class="line">                cv2.rectangle(image, (int_x, int_y), (int_x + int_winW, int_y + int_winH), (<span class="number">0</span>, <span class="number">255</span>, <span class="number">0</span>), <span class="number">1</span>)</span><br><span class="line">            cv2.imwrite(<span class="string">"E:/python/myInceptionProject/cut_img/"</span>+str(k)+<span class="string">".jpg"</span>,image)</span><br><span class="line">            k+=<span class="number">1</span></span><br></pre></td></tr></table></figure>
<p>检测图片是类似这种：</p>
<div align="center"><br><img src="/images/source_image.jpg" alt="source_image"><br></div><br><div align="center"><br>&gt; 图为：视频某一帧，效果见目录位置<br></div>


<p>当然，像所有论文作者一样，我只是贴出了效果比较明显的图片，其实如果不加入非极大值抑制，会得到如下结果</p>
<div align="center"><br><img src="/images/no_nms.jpg" alt="4"><br></div><br><div align="center"><br>&gt; 图为：不加非极大值抑制<br></div>

<p>会有很多检测结果并不好，像下面图片，首先检测框款选的位置还是有点偏差，此外寸头男子就没有检测出来，倒是把手给框出来了，这是因为训练时候没有短头发的样本放进去….</p>
<div align="center"><br><img src="/images/bad_result.jpg" alt="7"><br></div><br><div align="center"><br>&gt; 图为：检测效果不明显<br></div>

<p>此外最最重要的是，Inception V3的网络结构很大，而且并不是专门用于检测人流的网络，它检测客流就明显不具有实时性，基本只能检测几百张图片这样。如果存入太多帧图片到session中，会报错如下：<br>    raise ValueError(“GraphDef cannot be larger than 2GB.”)<br>ValueError: GraphDef cannot be larger than 2GB.</p>
<p>会话不能加载太多图片，所以只能部分图片部分图片地读到会话中，而不能直接把视频读进去，这样处理虽然也可以得到最后结果，然后整合输出视频，但是实在是太慢。</p>
<h1><span id="结论">结论</span></h1><p>可以检测出人流，但是效果一般，而且实时性太差，所以转战yolo，想看的请出门走转。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/child/2019/05/10/Tensorflow-gpu训练手写数字pb模型文件，C-调用预测/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Allent Dan">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Allent's Blogs">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/05/10/Tensorflow-gpu训练手写数字pb模型文件，C-调用预测/" itemprop="url">Tensorflow_gpu训练手写数字pb模型文件，C++调用预测</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-05-10T10:47:11+08:00">
                2019-05-10
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1><span id="tensorflow_gpu训练手写数字pb模型文件c调用预测">Tensorflow_gpu训练手写数字pb模型文件，C++调用预测</span></h1><p>没啥好说，直接上代码</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br></pre></td><td class="code"><pre><span class="line"># -*- coding: utf-8 -*-</span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line">Created on Mon May  6 09:50:41 2019</span><br><span class="line"></span><br><span class="line">@author: admin</span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line"># Python3</span><br><span class="line"></span><br><span class="line"># 使用LeNet5的七层卷积神经网络用于MNIST手写数字识别</span><br><span class="line"></span><br><span class="line">import os</span><br><span class="line">import tensorflow as tf</span><br><span class="line">from tensorflow.examples.tutorials.mnist import input_data</span><br><span class="line"></span><br><span class="line">mnist = input_data.read_data_sets(&quot;MNIST_data&quot;, one_hot=True)</span><br><span class="line">pb_file_path = os.getcwd()   #获取当前代码路径</span><br><span class="line"></span><br><span class="line"># 为输入图像和目标输出类别创建节点</span><br><span class="line">tf.reset_default_graph()</span><br><span class="line">x = tf.placeholder(tf.float32, shape=[None, 784],name=&apos;x&apos;) # 训练所需数据  占位符</span><br><span class="line">y_ = tf.placeholder(tf.float32, shape=[None, 10]) # 训练所需标签数据  占位符</span><br><span class="line"></span><br><span class="line"># *************** 构建多层卷积网络 *************** #</span><br><span class="line"></span><br><span class="line"># 权重、偏置、卷积及池化操作初始化,以避免在建立模型的时候反复做初始化操作</span><br><span class="line">def weight_variable(shape):</span><br><span class="line">  initial = tf.truncated_normal(shape, stddev=0.1) # 取随机值，符合均值为0，标准差stddev为0.1</span><br><span class="line">  return tf.Variable(initial)</span><br><span class="line"></span><br><span class="line">def bias_variable(shape):</span><br><span class="line">  initial = tf.constant(0.1, shape=shape)</span><br><span class="line">  return tf.Variable(initial)</span><br><span class="line"></span><br><span class="line"># x 的第一个参数为图片的数量，第二、三个参数分别为图片高度和宽度，第四个参数为图片通道数。</span><br><span class="line"># W 的前两个参数为卷积核尺寸，第三个参数为图像通道数，第四个参数为卷积核数量</span><br><span class="line"># strides为卷积步长，其第一、四个参数必须为1，因为卷积层的步长只对矩阵的长和宽有效</span><br><span class="line"># padding表示卷积的形式，即是否考虑边界。&quot;SAME&quot;是考虑边界，不足的时候用0去填充周围，&quot;VALID&quot;则不考虑</span><br><span class="line">def conv2d(x, W):</span><br><span class="line">  return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding=&apos;SAME&apos;)</span><br><span class="line"></span><br><span class="line"># x 参数的格式同tf.nn.conv2d中的x，ksize为池化层过滤器的尺度，strides为过滤器步长</span><br><span class="line">def max_pool_2x2(x):</span><br><span class="line">  return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=&apos;SAME&apos;)</span><br><span class="line"></span><br><span class="line">#把x更改为4维张量，第1维代表样本数量，第2维和第3维代表图像长宽， 第4维代表图像通道数  </span><br><span class="line">x_image = tf.reshape(x, [-1,28,28,1]) # -1表示任意数量的样本数,大小为28x28，深度为1的张量</span><br><span class="line"></span><br><span class="line"># 第一层：卷积</span><br><span class="line">W_conv1 = weight_variable([5, 5, 1, 32]) # 卷积在每个5x5的patch中算出32个特征。</span><br><span class="line">b_conv1 = bias_variable([32])</span><br><span class="line"></span><br><span class="line">h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1) </span><br><span class="line"></span><br><span class="line"># 第二层：池化</span><br><span class="line">h_pool1 = max_pool_2x2(h_conv1)</span><br><span class="line"></span><br><span class="line"># 第三层：卷积</span><br><span class="line">W_conv2 = weight_variable([5, 5, 32, 64])</span><br><span class="line">b_conv2 = bias_variable([64])</span><br><span class="line"></span><br><span class="line">h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)</span><br><span class="line"></span><br><span class="line"># 第四层：池化</span><br><span class="line">h_pool2 = max_pool_2x2(h_conv2)</span><br><span class="line"></span><br><span class="line"># 第五层：全连接层</span><br><span class="line">W_fc1 = weight_variable([7 * 7 * 64, 1024])</span><br><span class="line">b_fc1 = bias_variable([1024])</span><br><span class="line"></span><br><span class="line">h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])</span><br><span class="line">h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)</span><br><span class="line"></span><br><span class="line"># 在输出层之前加入dropout以减少过拟合</span><br><span class="line">keep_prob = tf.placeholder(tf.float32, name=&quot;keep_prob&quot;)</span><br><span class="line">h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)</span><br><span class="line"></span><br><span class="line"># 第六层：全连接层</span><br><span class="line">W_fc2 = weight_variable([1024, 10])</span><br><span class="line">b_fc2 = bias_variable([10])</span><br><span class="line"></span><br><span class="line"># 第七层：输出层</span><br><span class="line">y_conv=tf.nn.softmax(tf.matmul(h_fc1_drop, W_fc2) + b_fc2,name=&apos;y&apos;)</span><br><span class="line"></span><br><span class="line"># *************** 训练和评估模型 *************** #</span><br><span class="line"></span><br><span class="line"># 为训练过程指定最小化误差用的损失函数，即目标类别和预测类别之间的交叉熵</span><br><span class="line">cross_entropy = -tf.reduce_sum(y_*tf.log(y_conv))</span><br><span class="line"></span><br><span class="line"># 使用反向传播，利用优化器使损失函数最小化</span><br><span class="line">train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)</span><br><span class="line"></span><br><span class="line"># 检测我们的预测是否真实标签匹配(索引位置一样表示匹配)</span><br><span class="line"># tf.argmax(y_conv,dimension), 返回最大数值的下标 通常和tf.equal()一起使用，计算模型准确度</span><br><span class="line"># dimension=0 按列找  dimension=1 按行找</span><br><span class="line">correct_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(y_,1))  </span><br><span class="line"></span><br><span class="line"># 统计测试准确率， 将correct_prediction的布尔值转换为浮点数来代表对、错，并取平均值。</span><br><span class="line">accuracy = tf.reduce_mean(tf.cast(correct_prediction, &quot;float&quot;))</span><br><span class="line"></span><br><span class="line">saver = tf.train.Saver() # 定义saver</span><br><span class="line"></span><br><span class="line"># *************** 开始训练模型 *************** #</span><br><span class="line">with tf.Session() as sess:</span><br><span class="line">    sess.run(tf.global_variables_initializer())</span><br><span class="line"></span><br><span class="line">    for i in range(1002):</span><br><span class="line">      batch = mnist.train.next_batch(50)</span><br><span class="line">      if i%100 == 0:</span><br><span class="line">          </span><br><span class="line">          # 评估模型准确度，此阶段不使用Dropout</span><br><span class="line">          train_accuracy = accuracy.eval(feed_dict=&#123;x:batch[0], y_: batch[1], keep_prob: 1.0&#125;)</span><br><span class="line">          print(&quot;step %d, training accuracy %g&quot;%(i, train_accuracy))</span><br><span class="line">      # 训练模型，此阶段使用50%的Dropout</span><br><span class="line">      train_step.run(feed_dict=&#123;x: batch[0], y_: batch[1], keep_prob: 0.5&#125;) </span><br><span class="line">      if i%100 == 0:</span><br><span class="line">          constant_graph = tf.graph_util.convert_variables_to_constants(sess, sess.graph_def, [&apos;x&apos;,&apos;y&apos;,&apos;keep_prob&apos;])</span><br><span class="line">          with tf.gfile.FastGFile(&apos;e:\\model.pb&apos;, mode=&apos;wb&apos;) as f: #模型的名字是model.pb</span><br><span class="line">              f.write(constant_graph.SerializeToString())</span><br><span class="line">    saver.save(sess, &apos;./save/model.ckpt&apos;) #模型储存位置</span><br><span class="line"></span><br><span class="line">    print(&quot;test accuracy %g&quot;%accuracy.eval(feed_dict=&#123;x: mnist.test.images [0:2000], y_: mnist.test.labels [0:2000], keep_prob: 1.0&#125;))</span><br></pre></td></tr></table></figure>
<p>训练会生成pb文件，到e:\model.pb，随后用python调用，调用代码如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"># -*- coding: utf-8 -*-</span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line">Created on Mon May  6 10:21:40 2019</span><br><span class="line"></span><br><span class="line">@author: admin</span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">from PIL import Image</span><br><span class="line">import tensorflow as tf</span><br><span class="line">from tensorflow.python.platform import gfile</span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line">im = Image.open(&apos;C:\\Users\\admin\\Pictures\\3.png&apos;)</span><br><span class="line">data = list(im.getdata())</span><br><span class="line">result = [(255-x)*1.0/255.0 for x in data] </span><br><span class="line">#print(result)</span><br><span class="line"></span><br><span class="line"># 为输入图像和目标输出类别创建节点</span><br><span class="line">tf.reset_default_graph()</span><br><span class="line">#x = tf.placeholder(&quot;float&quot;, shape=[None, 784]) # 训练所需数据  占位符</span><br><span class="line"></span><br><span class="line"># *************** 开始识别 *************** #</span><br><span class="line">with tf.Session() as sess:</span><br><span class="line">    sess.run(tf.global_variables_initializer())</span><br><span class="line">    with gfile.FastGFile(&apos;e:\\model.pb&apos;, &apos;rb&apos;) as f:</span><br><span class="line">        graph_def = tf.GraphDef()</span><br><span class="line">        graph_def.ParseFromString(f.read())</span><br><span class="line">        sess.graph.as_default()</span><br><span class="line">        tf.import_graph_def(graph_def, name=&apos;&apos;)</span><br><span class="line">    x = sess.graph.get_tensor_by_name(&quot;x:0&quot;)</span><br><span class="line">    y = sess.graph.get_tensor_by_name(&quot;y:0&quot;)</span><br><span class="line">    keep_prob = sess.graph.get_tensor_by_name(&quot;keep_prob:0&quot;)</span><br><span class="line">   # print(test) </span><br><span class="line">    #saver.restore(sess, &quot;./save/model.ckpt&quot;)#这里使用了之前保存的模型参数</span><br><span class="line"></span><br><span class="line">    prediction = tf.argmax(y,1)</span><br><span class="line">    predint = prediction.eval(feed_dict=&#123;x: [result],keep_prob: 1.0&#125;, session=sess)</span><br><span class="line"></span><br><span class="line">    print(&quot;recognize result: %d&quot; %predint[0])</span><br></pre></td></tr></table></figure>
<p>使用到的图片是这个，你可以自己下载直接用，也可以手写然后用OpenCV处理得到28*28的灰度图片。</p>
<div align="center"><br><img src="\images\3_mnist.png" alt="3"><br></div>

<h1><span id="visual-c调用pb文件预测">Visual C++调用pb文件预测</span></h1><p>也是直接上代码</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br></pre></td><td class="code"><pre><span class="line">#define COMPILER_MSVC</span><br><span class="line">#define NOMINMAX</span><br><span class="line">#define PLATFORM_WINDOWS</span><br><span class="line"></span><br><span class="line">#include &lt;fstream&gt;</span><br><span class="line"></span><br><span class="line">#include &lt;utility&gt;</span><br><span class="line">#include&lt;vector&gt;</span><br><span class="line">#include&lt;string&gt;</span><br><span class="line"></span><br><span class="line">#include&lt;opencv2/opencv.hpp&gt;</span><br><span class="line">#include&quot;tensorflow/core/public/session.h&quot;</span><br><span class="line">#include &quot;tensorflow/core/platform/env.h&quot;</span><br><span class="line">#include &quot;tensorflow/core/graph/default_device.h&quot;</span><br><span class="line">#include &quot;tensorflow/cc/ops/standard_ops.h&quot;</span><br><span class="line"></span><br><span class="line">using namespace tensorflow;</span><br><span class="line">using tensorflow::Tensor;</span><br><span class="line">using std::cout;</span><br><span class="line">using std::endl;</span><br><span class="line"></span><br><span class="line">int main() &#123;</span><br><span class="line">	// 设置输入图像</span><br><span class="line">	cv::Mat img = cv::imread(&quot;C:\\Users\\admin\\Pictures\\3.png&quot;);</span><br><span class="line">	cv::cvtColor(img, img, cv::COLOR_BGR2GRAY);</span><br><span class="line">	int height = img.rows;</span><br><span class="line">	int width = img.cols;</span><br><span class="line">	int depth = img.channels();</span><br><span class="line">	cv::Mat img_transpose = img.t();</span><br><span class="line"></span><br><span class="line">	// 取图像数据，赋给tensorflow支持的Tensor变量中</span><br><span class="line">	const float* source_data = (float*)img.data;</span><br><span class="line">	cout&lt;&lt;source_data[1]&lt;&lt;endl;</span><br><span class="line">	tensorflow::Tensor input_tensor(DT_FLOAT, TensorShape(&#123; 1, height, width ,1 &#125;)); //这里只输入一张图片，参考tensorflow的数据格式NHWC</span><br><span class="line">	auto input_tensor_mapped = input_tensor.tensor&lt;float,4&gt;(); // input_tensor_mapped相当于input_tensor的数据接口，“4”表示数据是4维的。后面取出最终结果时也能看到这种用法                                                                                                      </span><br><span class="line"></span><br><span class="line">	// 把数据复制到input_tensor_mapped中，实际上就是遍历opencv的Mat数据</span><br><span class="line">	for (int i = 0; i &lt; height; i++) &#123;</span><br><span class="line">		for (int j = 0; j &lt; width; j++) &#123;</span><br><span class="line">			input_tensor_mapped(0, i, j ,0) = (255- img.at&lt;uchar&gt;(i, j))/255.0;</span><br><span class="line">			</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	// 初始化tensorflow session</span><br><span class="line">	Session* session;</span><br><span class="line">	Status status = NewSession(SessionOptions(), &amp;session);</span><br><span class="line">	if (!status.ok()) &#123;</span><br><span class="line">		std::cerr &lt;&lt; status.ToString() &lt;&lt; endl;</span><br><span class="line">		return -1;</span><br><span class="line">	&#125;</span><br><span class="line">	else &#123;</span><br><span class="line">		cout &lt;&lt; &quot;Session created successfully&quot; &lt;&lt; endl;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">	// 读取二进制的模型文件到graph中</span><br><span class="line">	GraphDef graph_def;</span><br><span class="line">	status = ReadBinaryProto(Env::Default(), &quot;e:\\model.pb&quot;, &amp;graph_def);</span><br><span class="line">	if (!status.ok()) &#123;</span><br><span class="line">		std::cerr &lt;&lt; status.ToString() &lt;&lt; endl;</span><br><span class="line">		return -1;</span><br><span class="line">	&#125;</span><br><span class="line">	else &#123;</span><br><span class="line">		cout &lt;&lt; &quot;Load graph protobuf successfully&quot; &lt;&lt; endl;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">	// 将graph加载到session</span><br><span class="line">	status = session-&gt;Create(graph_def);</span><br><span class="line">	if (!status.ok()) &#123;</span><br><span class="line">		std::cerr &lt;&lt; status.ToString() &lt;&lt; endl;</span><br><span class="line">		return -1;</span><br><span class="line">	&#125;</span><br><span class="line">	else &#123;</span><br><span class="line">		cout &lt;&lt; &quot;Add graph to session successfully&quot; &lt;&lt; endl;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	tensorflow::Tensor keep_prob(DT_FLOAT, TensorShape());</span><br><span class="line">	keep_prob.scalar&lt;float&gt;()() = 1.0;</span><br><span class="line">	std::vector&lt;std::pair&lt;std::string, tensorflow::Tensor&gt;&gt; inputs = &#123;</span><br><span class="line">		&#123; &quot;x&quot;, input_tensor &#125;,</span><br><span class="line">		&#123; &quot;keep_prob&quot;, keep_prob &#125;,</span><br><span class="line">	&#125;;</span><br><span class="line"></span><br><span class="line">	// 输出outputs</span><br><span class="line">	std::vector&lt;tensorflow::Tensor&gt; outputs;</span><br><span class="line"></span><br><span class="line">	// 运行会话，计算输出&quot;x_predict&quot;，即我在模型中定义的输出数据名称，最终结果保存在outputs中</span><br><span class="line">	auto input_shape = input_tensor.shape();</span><br><span class="line">	status = session-&gt;Run(inputs, &#123; &quot;y&quot; &#125;, &#123;&#125;, &amp;outputs);</span><br><span class="line">	if (!status.ok()) &#123;</span><br><span class="line">		std::cerr &lt;&lt; status.ToString() &lt;&lt; endl;</span><br><span class="line">		system(&quot;pause&quot;);</span><br><span class="line">		return -1;</span><br><span class="line">	&#125;</span><br><span class="line">	else &#123;</span><br><span class="line">		cout &lt;&lt; &quot;Run session successfully&quot; &lt;&lt; endl;</span><br><span class="line">	&#125;</span><br><span class="line">	// 下面进行输出结果的可视化</span><br><span class="line">	tensorflow::Tensor output = std::move(outputs.at(0)); // 模型只输出一个结果，这里首先把结果移出来（也为了更好的展示）</span><br><span class="line">	auto out_shape = output.shape(); // 这里的输出结果为1x4x16</span><br><span class="line">	auto out_val = output.tensor&lt;float, 2&gt;(); // 与开头的用法对应，3代表结果的维度</span><br><span class="line">	// cout &lt;&lt; out_val.argmax(2) &lt;&lt; &quot; &quot;; // 预测结果，与python一致，但具体数值有差异，猜测是计算精度不同造成的</span><br><span class="line">	cout &lt;&lt;&quot;Output tensor shape:&quot;&lt;&lt; output.shape()&lt;&lt;endl;</span><br><span class="line">	for (int j = 0; j &lt; out_shape.dim_size(1); j++) &#123;</span><br><span class="line">		cout &lt;&lt; out_val(0, j) &lt;&lt; &quot; &quot;;</span><br><span class="line">	&#125;</span><br><span class="line">	cout &lt;&lt; &quot;size:&quot; &lt;&lt; out_shape.dim_size(1)&lt;&lt;endl;</span><br><span class="line">	cout &lt;&lt;&quot;Prediction value:&quot;&lt;&lt; out_val.argmax(1)&lt;&lt;endl;</span><br><span class="line">	system(&quot;pause&quot;);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>相关配置都有在前两篇博客写过，就不赘述了。这里要说下CUDA配置完Tensorflow C++使用坑爹的地方，如果你同时开着python的tensorflowIDE环境，它会分出部分GPU内存给该环境，但是如果你用上面的代码运行测试，会发现报内存超出的错。</p>
<div align="center"><br><img src="\images\normal.PNG" alt="normal"><br></div>

<p>正常调用会这样，但是开着其他环境，就报错：</p>
<div align="center"><br><img src="\images\abnormal.PNG" alt="abnormal"><br></div>

<p>CUDA_ERROR_OF_MEMORY，然后更坑爹的是我的c++无法同python一样指定gpu内存分配，会报unresolved external symbol错误，也就是未解析的外部符号。解决办法就一个，关掉其他gpu进程。</p>
<p>预测结果如下：</p>
<div align="center"><br><img src="\images\c++预测.PNG" alt="c++预测"><br></div>

<p>细节回去再更….</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">Allent Dan</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">11</span>
                  <span class="site-state-item-name">posts</span>
                </a>
              </div>
            

            

            
              
              
              <div class="site-state-item site-state-tags">
                
                  <span class="site-state-item-count">5</span>
                  <span class="site-state-item-name">tags</span>
                
              </div>
            

          </nav>

          

          

          
          

          
          

          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Allent Dan</span>

  
</div>


  <div class="powered-by">Powered by <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a></div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Muse</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  





  

  

  

  
  

  

  

  

</body>
</html>
